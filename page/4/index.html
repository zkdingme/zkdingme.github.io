<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
   
  <meta name="keywords" content="丁星乐、学习、工作、生活" />
   
  <meta name="description" content="分享丁星乐的学习、工作与享乐时光" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
     丁星乐
  </title>
  <meta name="generator" content="hexo-theme-yilia-plus">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  
<link rel="stylesheet" href="/css/style.css">

  
<script src="/js/pace.min.js"></script>


  

  

</head>

</html>

<body>
  <div id="app">
    <main class="content">
      
<section class="cover">
    
      
      <a class="forkMe" href="https://github.com/dingzhenkai"
        target="_blank"><img width="149" height="149" src="/images/forkme.png"
          class="attachment-full size-full" alt="Fork me on GitHub" data-recalc-dims="1"></a>
    
  <div class="cover-frame">
    <div class="bg-box">
      <img src="/images/cover.jpg" alt="image frame" />
    </div>
    <div style="color:#000" class="cover-inner text-center text-white">
      <h1><a style="color:#000" href="/">丁星乐</a></h1>
      <div id="subtitle-box">
        
        <span id="subtitle"></span>
        
      </div>
      <div>
        
      </div>
    </div>
  </div>
  <div class="cover-learn-more">
    <a href="javascript:void(0)" class="anchor"><i class="ri-arrow-down-line"></i></a>
  </div>
</section>


<div id="main">
  <section class="outer">
  <article class="articles">
    
    
    
    
    <article id="post-发现异常" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/10/12/%E5%8F%91%E7%8E%B0%E5%BC%82%E5%B8%B8/"
    >发现异常</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/10/12/%E5%8F%91%E7%8E%B0%E5%BC%82%E5%B8%B8/" class="article-date">
  <time datetime="2020-10-12T02:56:21.000Z" itemprop="datePublished">2020-10-12</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/">数据挖掘</a>
  </div>

      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <ul>
<li>根据已有异常关联未发现的异常<br>ip在黑名单的用户的其他特征像wifi数量、设备指纹和登陆时间段都可能是异常</li>
<li>随时间变化不稳定<br>正常用户的属性随时间变化都是稳定的，异常用户是不稳定的</li>
<li>聚类<br>正常人聚类在一起一大团，异常人聚类一小团</li>
</ul>

      
      <!-- 打赏 -->
      
    </div>
    <footer class="article-footer">
      <a data-url="https://zkdingme.github.io/2020/10/12/%E5%8F%91%E7%8E%B0%E5%BC%82%E5%B8%B8/" data-id="ckse3iv1e004roqj536qyd9c8"
        class="article-share-link">分享</a>
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%8F%91%E7%8E%B0%E5%BC%82%E5%B8%B8/" rel="tag">发现异常</a></li></ul>

    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-Android-Dumpdex" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/09/30/Android-Dumpdex/"
    >Android 壳的背景知识</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/09/30/Android-Dumpdex/" class="article-date">
  <time datetime="2020-09-30T03:35:48.000Z" itemprop="datePublished">2020-09-30</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/Android/">Android</a>
  </div>

      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h2 id="背景知识"><a href="#背景知识" class="headerlink" title="背景知识"></a>背景知识</h2><p>壳是什么，为什么要脱壳，怎么脱壳？</p>
<p>壳是终端攻防的产物，最早在PC时代就出现了。最早是因为黑产会反编译得到应用程序的源码，然后魔改后重打包再投放到市场上去，这就是所谓的盗版软件，或者就直接在源码里面找到程序的漏洞例如支付漏洞，然后搞破坏。开发者们当然注意到了这些严重的漏洞，所以他们就给程序加壳来抵御黑产的攻击。壳这个名字就很形象的描述了这套防御机制，简单说就是在源码外面套了一层壳保护源码，黑产们想要获得源码需要先打破这层壳或者越过这层壳。加壳显著提高了黑产们获取源码的难度，缓解了之前源码裸奔的尴尬场景。当然攻防是S形向前发展的，当开发者们加壳之后，黑产们很快就研究出了破壳或者说脱壳的方法，开发者们也紧跟着推出了新一代的壳，就这样道高一尺魔高一丈然后又魔高一尺道高一丈相爱相杀。总体来说，壳这个机制还是很有效的，虽然还是存在被脱壳的可能，但是在一次又一次的攻防中，脱壳的难度已经被拉高了太多，这个门槛已经比较高，还在坚持的黑产玩家已经不多了。当然壳也有其不好的一面，首先就是对性能的影响，壳太厚势必会拉低性能，某宝加壳后性能拉低了40-50倍，这还是不断优化后的结果。其次就是其他方面的安全性会降低，安全是一条链，这条链上有很多节点，终端app只是其中一个节点，这条链上还有很多别的节点，任何一颗节点被攻破都会造成大大小小的损失。你在终端壳上投入巨大势必其他方面投入就小了，黑产发现攻你app太难了，肯定就转头去试试你的服务器了。</p>
<p>移动端兴起之后，这套玩法也传承了下来，早期市场上充斥着大量的盗版软件，尤其是游戏领域，全是内购破解的。现在脱壳也还是很火，比较热门的就是脱一些短视频平台的壳，逆向出网络协议，然后写脚本刷关注、刷播放量。</p>
<h2 id="如何脱壳"><a href="#如何脱壳" class="headerlink" title="如何脱壳"></a>如何脱壳</h2><p>宗旨是无论你如何加壳，代码总归是要运行的，总归是要明文出现在内存里面的，脱壳就是在适当的时机把内存里面的代码dump出来。Android领域脱壳方案有很多种，像Fart、Youpk、DexHunter等，具体可在看雪平台搜索相应脱壳方案与其原理，这里不做描述。笔者只尝试过原始的ida动态定位dex地址并dump内存方案、Fart方案和基于frida的方案，在当时确实能dump出源码，还是挺有趣的。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>我个人并不看好壳的未来，首先是对性能影响太大，其次是Android上的壳发展到现在已经很难破了例如VMP，再继续搞新壳难度太大也没必要，最后是现在的大势是一切上云，云手机是未来(手机算力不如服务器，现在美国还卡芯片，之后会专门讲一期云手机)，云手机就意味着大家之后的手机就是个显示屏+遥控器，app运行在服务器上做计算和渲染，到时候黑产根本就拿不到apk，跟别提脱壳了。</p>
<p>不过就算壳没了，黑产也不会消失，攻防这场战争是无止尽的。</p>

      
      <!-- 打赏 -->
      
    </div>
    <footer class="article-footer">
      <a data-url="https://zkdingme.github.io/2020/09/30/Android-Dumpdex/" data-id="ckse3iuyw0000oqj5bpnp0wiw"
        class="article-share-link">分享</a>
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%84%B1%E5%A3%B3/" rel="tag">脱壳</a></li></ul>

    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-android-type3-error" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/09/29/android-type3-error/"
    >Error type 3 Error Activity class {} does not exist</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/09/29/android-type3-error/" class="article-date">
  <time datetime="2020-09-28T16:20:48.000Z" itemprop="datePublished">2020-09-29</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/Android/">Android</a>
  </div>

      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <p>Android Studio debug 安装 app 到手机上时，有时会安装失败，报错如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">09&#x2F;29 00:22:11: Launching app</span><br><span class="line">$ adb shell am start -n &quot;me.zkding.btdemo&#x2F;me.zkding.btdemo.activity.BluetoothChat&quot; -a android.intent.action.MAIN -c android.intent.category.LAUNCHER</span><br><span class="line">Error while executing: am start -n &quot;me.zkding.btdemo&#x2F;me.zkding.btdemo.activity.BluetoothChat&quot; -a android.intent.action.MAIN -c android.intent.category.LAUNCHER</span><br><span class="line">Starting: Intent &#123; act&#x3D;android.intent.action.MAIN cat&#x3D;[android.intent.category.LAUNCHER] cmp&#x3D;me.zkding.btdemo&#x2F;.activity.BluetoothChat &#125;</span><br><span class="line">Error type 3</span><br><span class="line">Error: Activity class &#123;me.zkding.btdemo&#x2F;me.zkding.btdemo.activity.BluetoothChat&#125; does not exist.</span><br><span class="line"></span><br><span class="line">Error while Launching activity</span><br></pre></td></tr></table></figure>

<p>这个问题StackOverflow上就有人问过，也有人给出了<a href="https://stackoverflow.com/questions/20915266/error-type-3-error-activity-class-does-not-exist" target="_blank" rel="noopener">建议</a>, 但对我都不work。</p>
<p>苦恼许久我才发现，原来是我之前debug时候装了一个apk在手机上，然后卸载的时候是手动卸载的(华为长按卸载)，然后再次安装同样的debug包就会报这个错。解决方法是 <code>adb uninstall me.zkding.btdemo</code> ，然后再安装就可以了。应该是手动卸载有什么东西没卸载干净，不过我暂时没时间细究，留个TODO。</p>

      
      <!-- 打赏 -->
      
    </div>
    <footer class="article-footer">
      <a data-url="https://zkdingme.github.io/2020/09/29/android-type3-error/" data-id="ckse3iuzn0013oqj55hxxhis5"
        class="article-share-link">分享</a>
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Debug/" rel="tag">Debug</a></li></ul>

    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-ssh-remote-tunnel" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/09/26/ssh-remote-tunnel/"
    >ssh remote tunnel 介绍</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/09/26/ssh-remote-tunnel/" class="article-date">
  <time datetime="2020-09-26T12:53:24.000Z" itemprop="datePublished">2020-09-26</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E7%BD%91%E7%BB%9C/">网络</a>
  </div>

      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <p><strong>转载自 <a href="https://blog.csdn.net/blade2001/article/details/8877250" target="_blank" rel="noopener">https://blog.csdn.net/blade2001/article/details/8877250</a></strong></p>
<p>SSH的的Port Forward，中文可以称为端口转发，是SSH的一项非常重要的功能。它可以建立一条安全的SSH通道，并把任意的TCP连接放到这条通道中。下面仔细就仔细讨论SSH的这种非常有用的功能。</p>
<p>SSH Tunnel有三种，分别是本地Local（ssh -NfL），远程Remote（ssh -NfR），动态Dynamic（ssh -NfD）。（含义参考<a href="http://linux.die.net/man/1/ssh" target="_blank" rel="noopener">man ssh</a>）</p>
<p>说明：在我们举例说明用法之前，先假设你有一台SSH机器，它的IP是a.b.c.d。</p>
<p>1：本地Local（ssh -NfL）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -L &lt;local port&gt;:&lt;remote host&gt;:&lt;remote port&gt; &lt;SSH hostname&gt;</span><br></pre></td></tr></table></figure>

<p>ssh -NfL a.b.c.d : 1234 : <a href="http://www.google.com" target="_blank" rel="noopener">www.google.com</a> : 80  a.b.c.d</p>
<p>此时，在浏览器里键入：<a href="http://a.b.c.d:1234" target="_blank" rel="noopener">http://a.b.c.d:1234</a> 就会看到Google的页面了。</p>
<p>在绑定1234端口的时候，可以省略前面的ip，如此一来，1234端口就仅仅绑定在localhost地址上，更安全：</p>
<p>ssh -NfL 1234 : <a href="http://www.google.com" target="_blank" rel="noopener">www.google.com</a> : 80  a.b.c.d</p>
<p>此时浏览的话就要在a.b.c.d机器上使用<a href="http://localhost:1234" target="_blank" rel="noopener">http://localhost:1234</a> 了。</p>
<p><strong><em>\</em>何时使用本地Tunnel？\</strong></p>
<p>*<em>比如说你在本地访问不了某个网络服务（如<a href="http://www.google.com" target="_blank" rel="noopener">www.google.com</a> ，而有一台机器（如：a.b.c.d）可以，那么你就可以通过这台机器来访问。***</em></p>
<p>2：远程Remote（ssh -NfR）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -R &lt;local port&gt;:&lt;remote host&gt;:&lt;remote port&gt; &lt;SSH hostname&gt;</span><br></pre></td></tr></table></figure>

<p>在需要被访问的内网机器上运行： ssh -NfR 1234 : localhost : 22  a.b.c.d</p>
<p>登录到a.b.c.d机器，使用如下命令连接内网机器：</p>
<p>ssh -p 1234  localhost</p>
<p>需要注意的是上下两个命令里的localhost不是同一台。这时你会发现自己已经连上最开始命令里的localhost机器了，也就是执行“ssh -NfR”的那台机器。</p>
<p><strong><em>\</em>何时使用远程Tunnel？\</strong></p>
<p>*<em>比如当你下班回家后就访问不了公司内网的机器了，遇到这种情况可以事先在公司内网的机器上执行远程Tunnel，连上一台公司外网的机器，等你下班回家后 就可以通过公司外网的机器去访问公司内网的机器了。***</em></p>
<p>3：动态Dynamic（ssh -NfD）<strong>-\</strong>Socket代理****</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -D</span><br></pre></td></tr></table></figure>

<p>ssh -NfD 1234  a.b.c.d</p>
<p>a.b.c.c 是server 地址</p>
<p>如此一来就建立了一台Socket代理机器，接着在浏览器上设置Socket代理：地址是localhost，端口是1234，从此以后，你的访问都是加 密的了！你可以通过访问 <a href="http://www.whatismyip.com/" target="_blank" rel="noopener">WhatIsMyIP</a> 来 确认自己现在的IP，看看是不是已经变成a.b.c.d了。</p>
<p>测试阶段，也可以把端口绑定在外网地址上，如此一来，你在浏览器上就可以使用外网地址设置Socket代理，但这仅限于测试，否则，你的机器就不安全了， 随时可能成为肉鸡。对于Windows用户来说，如果讨厌命令行，还可以使用MyEnTunnel来实现同样的功能，配合Firefox的 FoxyPorxy，基本就无敌了，至于具体的配置方法，小崔已经写好了： <a href="http://fendou.org/2010/01/19/firefox-foxyproxy-ssh/" target="_blank" rel="noopener">使用Firefox+foxyProxy+SSH翻山越岭</a> 。如果你使用的是Chrome的话，则可以选择 Proxy Switchy!来实现同样的效果，恕不多言。</p>

      
      <!-- 打赏 -->
      
    </div>
    <footer class="article-footer">
      <a data-url="https://zkdingme.github.io/2020/09/26/ssh-remote-tunnel/" data-id="ckse3iv12003noqj59p9zamur"
        class="article-share-link">分享</a>
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ssh-tunnel/" rel="tag">ssh tunnel</a></li></ul>

    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-batch为啥快" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/09/26/batch%E4%B8%BA%E5%95%A5%E5%BF%AB/"
    >batch为啥快</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/09/26/batch%E4%B8%BA%E5%95%A5%E5%BF%AB/" class="article-date">
  <time datetime="2020-09-26T09:54:30.000Z" itemprop="datePublished">2020-09-26</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80%E6%9D%82%E8%B0%88/">计算机基础杂谈</a>
  </div>

      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <p>batch其实不一定快，所谓快，一个是throughput，一个是latency。batch的throughput肯定更高，但是latency也更高，所以这也算是个tradeoff。</p>
<p>那batch的throughput为什么会更高呢？简单说，batch读的时候cache hit率会更高，batch写的时候寻址会更快，也许会写到同一个block里面。</p>

      
      <!-- 打赏 -->
      
    </div>
    <footer class="article-footer">
      <a data-url="https://zkdingme.github.io/2020/09/26/batch%E4%B8%BA%E5%95%A5%E5%BF%AB/" data-id="ckse3iuzs001foqj5fgmvfmjp"
        class="article-share-link">分享</a>
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%89%B9%E5%A4%84%E7%90%86/" rel="tag">批处理</a></li></ul>

    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-DeFi" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/09/15/DeFi/"
    >DeFi</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/09/15/DeFi/" class="article-date">
  <time datetime="2020-09-15T04:21:17.000Z" itemprop="datePublished">2020-09-15</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%8C%BA%E5%9D%97%E9%93%BE/">区块链</a>
  </div>

      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h2 id="DeFi是什么"><a href="#DeFi是什么" class="headerlink" title="DeFi是什么"></a>DeFi是什么</h2><p>去中心化的金融，可以理解为区块链领域的金融。举例说，我持有100万人民币，但是暂时不需要花，那我肯定选择去把钱存银行吃利息或者去买点股票基金啥的，让钱生点钱，一年后我的100万就变成了110万，我很开心。那在区块链领域，我持有100个BTC，除了等BTC从1万美元升值到2万美元外，并没有像现实社会中理财的方式，简单说，我的100BTC一年后还是100个BTC，不会变成110个BTC。基于这个需求，DeFi就出现了。</p>
<p>DeFi只是一个概念，落到实处就是一个一个具体的DeFI项目。什么是DeFi项目，对比现实社会就是债券、股票、基金、银行存钱这些理财项目，本质上就是你投资他们，他们赚钱之后给你返利。我简单举三个例子说明一下：</p>
<ul>
<li>项目A，年化10%。区块链领域一家大的矿池说，我想扩张，做东半球最大的矿池，但是我现在钱不够，大家给我投点钱，我去扩张，等我成了东半球最大的矿池转了大钱，我分你钱。</li>
<li>项目B，年化50%。区块链领域的一家金融机构，专门炒币，当BTC低的时候买，高的时候抛。现在这家金融机构判断BTC已经到了底部，准备大举抄底，但是现在钱不够，只能抄一点，等之后涨起来估计也就赚个100W。现在他们说，大家借我点钱，我抄个底，等BTC涨上去我卖掉再把钱还给大家，还给大家一笔可观的分红。</li>
<li>项目C，年化5%。区块链领域的一家基金管理公司，对比现实社会中易方达、工银瑞信等。他们说，老乡们，外面的DeFi项目都是骗子，你别看项目A，项目B年化都10个点，50个点，他们风险很大的。你想想项目A万一扩张失败倒闭了，项目BTC一直下降不涨了，你的钱就没了呀。外面的DeFi项目那么多，有好有坏，老乡们哪有那么多精力去挑选一个高收益低风险的，不如把钱交给我，我全职帮你管理，我帮你们挑选合适的项目，帮你们理财，你们给我点工资就好，我给你们打工。</li>
</ul>
<p>总结一下，DeFi就是区块链领域的理财项目。</p>
<h2 id="怎么靠DeFi项目赚钱"><a href="#怎么靠DeFi项目赚钱" class="headerlink" title="怎么靠DeFi项目赚钱"></a>怎么靠DeFi项目赚钱</h2><p>这要看你的身份。</p>
<p><strong>你是个投资者</strong></p>
<p>这没什么好说的，选一个靠谱的DeFi项目，把钱投进去就可以吃利息了。</p>
<p><strong>你是个创业者</strong></p>
<p>做一个基金管理公司，参考YFI/YFII/SUSHI。</p>
<p><a href="https://dfi.money/#/vault" target="_blank" rel="noopener">https://dfi.money/#/vault</a></p>
<p><a href="https://docs.yfii.finance/#/zh-cn/tuts" target="_blank" rel="noopener">https://docs.yfii.finance/#/zh-cn/tuts</a></p>
<p>大概就是fork一个这个池 <a href="https://docs.qq.com/doc/DUlpka0FXeGVMbkhm" target="_blank" rel="noopener">https://docs.qq.com/doc/DUlpka0FXeGVMbkhm</a></p>
<p>反正核心就简化用户投资的流程，不需要用户挑选DeFi项目</p>

      
      <!-- 打赏 -->
      
    </div>
    <footer class="article-footer">
      <a data-url="https://zkdingme.github.io/2020/09/15/DeFi/" data-id="ckse3iuz7000aoqj54ttf5wy6"
        class="article-share-link">分享</a>
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/DeFi/" rel="tag">DeFi</a></li></ul>

    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-bloom-filter-kiss" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/08/18/bloom-filter-kiss/"
    >11个问题帮你了解bloom filter</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/08/18/bloom-filter-kiss/" class="article-date">
  <time datetime="2020-08-18T06:03:35.000Z" itemprop="datePublished">2020-08-18</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/">数据结构</a>
  </div>

      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h3 id="1-bloom-filter是用来解决什么问题的"><a href="#1-bloom-filter是用来解决什么问题的" class="headerlink" title="1. bloom filter是用来解决什么问题的"></a>1. bloom filter是用来解决什么问题的</h3><p>快速查询元素a是否在集合A={a1,a2,..,an}里面，例如判断一个用户是否在黑名单中。</p>
<h3 id="2-简述bloom-filter的工作原理"><a href="#2-简述bloom-filter的工作原理" class="headerlink" title="2. 简述bloom filter的工作原理"></a>2. 简述bloom filter的工作原理</h3><ol>
<li>构建一个长度为m的bit array，初始化其中所有bit为0。</li>
<li>将集合A={a1,a2,..,an}中所有元素插入到bit array中。插入元素ai时，用k个hash函数算出k个位置，将对应位置的bit置为1。</li>
<li>为了查询元素a是否在集合A={a1,a2,..,an}中。同样用k个hash函数计算出a在bit array中的k个位置，如果这k个位置不全为1则a<strong>一定不在</strong>集合A中；如果全为1，则说明a<strong>可能</strong>在集合A中。这里存在false positive，因为对应k个位置的bit全为1可能是其他元素置的。</li>
</ol>
<p>如下图所示，构建了一个长度为16的bit array，将集合A中元素用3个hash函数计算位置并将对应bit置为1。查询a1时，同样计算3次hash发现对应位置bit全为1，因此判定a1可能在A中。对实际不在A的两个元素x、y，同样计算3次hash。x对应的3个bit全为1，bloom filter判定x可能在A中，但实际上x不在A中，x对应的三个bit是被a2、a3置为1的，这就造成了bloom filter的false positive；y对应的3个bit中有2个bit为0，因此bloom filter判定y一定不在A中。bloom filter不存在false negative，可以用反证法证明。如果存在false negative z，说明z实际在A中，那么z对应的bit全为1，那么bloom filter判断的结果应该是z可能在A中而不是不在，因此矛盾。</p>
<p><img src="bf.svg" alt=""></p>
<h3 id="3-Bloom-filter会有false-positive吗"><a href="#3-Bloom-filter会有false-positive吗" class="headerlink" title="3. Bloom filter会有false positive吗"></a>3. Bloom filter会有false positive吗</h3><p>会有，原因见问题2。</p>
<h3 id="4-Bloom-filter会有false-negative吗"><a href="#4-Bloom-filter会有false-negative吗" class="headerlink" title="4. Bloom filter会有false negative吗"></a>4. Bloom filter会有false negative吗</h3><p>不会有，原因见问题。</p>
<h3 id="5-bloom的误判率受什么影响"><a href="#5-bloom的误判率受什么影响" class="headerlink" title="5. bloom的误判率受什么影响"></a>5. bloom的误判率受什么影响</h3><p>最优k时，有$${\displaystyle \ln \varepsilon =-{\frac {m}{n}}\left(\ln 2\right)^{2}.}$$</p>
<p>显然，m越大，n越小，误判率越低。</p>
<h3 id="6-bit-array的大小m如何确定"><a href="#6-bit-array的大小m如何确定" class="headerlink" title="6. bit array的大小m如何确定"></a>6. bit array的大小m如何确定</h3><p>$$ m=-{\frac {n\ln \varepsilon }{(\ln 2)^{2}}} $$</p>
<p>其中n为数据集A的size，$\varepsilon$为指定的false positive possibility</p>
<table>
<thead>
<tr>
<th>$ \varepsilon $</th>
<th>m/n</th>
</tr>
</thead>
<tbody><tr>
<td>1/10</td>
<td>4.79</td>
</tr>
<tr>
<td>1/100</td>
<td>9.59</td>
</tr>
<tr>
<td>1/1000</td>
<td>14.38</td>
</tr>
<tr>
<td>1/10000</td>
<td>19.17</td>
</tr>
<tr>
<td>1/100000</td>
<td>23.96</td>
</tr>
<tr>
<td>1/1000000</td>
<td>28.76</td>
</tr>
<tr>
<td>1/10000000</td>
<td>33.55</td>
</tr>
<tr>
<td>1/100000000</td>
<td>38.34</td>
</tr>
<tr>
<td>1/1000000000</td>
<td>43.13</td>
</tr>
</tbody></table>
<p>可以看到 当误判率降低到10亿分之一时，bit array的size m也只是数据集长度的43倍</p>
<h3 id="7-hash轮数k如何确定"><a href="#7-hash轮数k如何确定" class="headerlink" title="7. hash轮数k如何确定"></a>7. hash轮数k如何确定</h3><p>$$k={\frac {m}{n}}\ln 2$$</p>
<p>其中m为bit array的size，n为数据集A的size</p>
<h3 id="8-hash轮数k与数据集A中单个数据的长度l有没有关系"><a href="#8-hash轮数k与数据集A中单个数据的长度l有没有关系" class="headerlink" title="8. hash轮数k与数据集A中单个数据的长度l有没有关系"></a>8. hash轮数k与数据集A中单个数据的长度l有没有关系</h3><p>有关系。hash轮数代表需要多少个bit来表示单个数据，在bloom filter中，表示单个数据需要k个bit。如果单个数据的长度l小于k个bit，那这种情况下用bloom filter就会造成空间的浪费，不划算。实际情况下，1%的false positive rate，9.6个bit就可以表示单个数据数据；0.1%的false positive rate，14.4个bit可以表示单个数据。这时候如果单个数据的长度小于14.4个bit，用bloom filter从空间开销上来说，就不划算了。</p>
<h3 id="9-对于查询一个元素是否在一个集合中这个问题，除了bloom-filter，你觉得还有什么解决方案，bloom-filter相比他们有什么优势有什么缺点"><a href="#9-对于查询一个元素是否在一个集合中这个问题，除了bloom-filter，你觉得还有什么解决方案，bloom-filter相比他们有什么优势有什么缺点" class="headerlink" title="9. 对于查询一个元素是否在一个集合中这个问题，除了bloom filter，你觉得还有什么解决方案，bloom filter相比他们有什么优势有什么缺点"></a>9. 对于查询一个元素是否在一个集合中这个问题，除了bloom filter，你觉得还有什么解决方案，bloom filter相比他们有什么优势有什么缺点</h3><p>我们需要考虑空间开销与查询时间开销以及正确率。空间开销的话，其他数据结构像数组、链表、平衡二叉搜索树、哈希表等都要存储源数据，相比于只需要一个bit array的bloom filter来说，肯定是不如的。时间开销的话，bloom filter的时间复杂度为O(k)，上述几种方案查询时间复杂度最优的是哈希表O(1)。因此我们对比一下哈希表与bloom filter。</p>
<p>主要对比三个方面：</p>
<ul>
<li>存储10W条大小为50byte的string需要多少空间</li>
<li>查询10W条相同数据与10万条不同数据需要多少时间</li>
<li>查询上面20W条数据正确率如何</li>
</ul>
<p>效果如下：</p>
<table>
<thead>
<tr>
<th></th>
<th>哈希表</th>
<th>bf(fpp=0.001)</th>
<th>bf(fpp=0.00001)</th>
<th>bf(fpp=0.0001)</th>
</tr>
</thead>
<tbody><tr>
<td>空间大小</td>
<td>12.44M</td>
<td>176K</td>
<td>293K</td>
<td>352K</td>
</tr>
<tr>
<td>查询时间</td>
<td>21ms</td>
<td>70ms</td>
<td>103ms</td>
<td>90ms</td>
</tr>
<tr>
<td>正确率(FP)</td>
<td>0</td>
<td>108</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>正确率(FN)</td>
<td>0</td>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody></table>
<p>可以看到bloom filter空间开销是哈希表的1/72～1/36，但是时间开销是哈希表的3～5倍。正确率方面bloom filter是有False Positive的。总结来说，bloom filter相比于其他解决方案的优势在于时间开销与空间开销都很低，适用于数据集特别大的查询场景；劣势在于有False Positive。</p>
<h3 id="10-Bloom-filter除了用来高效查询之外还可以用来干嘛"><a href="#10-Bloom-filter除了用来高效查询之外还可以用来干嘛" class="headerlink" title="10. Bloom filter除了用来高效查询之外还可以用来干嘛"></a>10. Bloom filter除了用来高效查询之外还可以用来干嘛</h3><ul>
<li>高效安全存储。bloom filter只需要10个bit就可以表示数据，对于一些不需要知道源数据或者源数据较为敏感的存储场景，可以使用bloom filter进行存储。例如门禁设备，存储所有人的指纹或者瞳纹在设备内部不是很安全，万一设备被盗了，所有人的指纹瞳纹就被泄露了，这种情况下，用bloom filter将所有人的指纹瞳纹存储为一个bit array就很合适。</li>
<li>复杂查询。bloom filter支持将bit array做交集或者并集后再进行查询。</li>
</ul>
<h3 id="11-Bloom-filter可以怎么被用在你的项目上"><a href="#11-Bloom-filter可以怎么被用在你的项目上" class="headerlink" title="11. Bloom filter可以怎么被用在你的项目上"></a>11. Bloom filter可以怎么被用在你的项目上</h3><p>略</p>
<h3 id="12-Bloom-filter是谁在什么时候发明的"><a href="#12-Bloom-filter是谁在什么时候发明的" class="headerlink" title="12. Bloom filter是谁在什么时候发明的"></a>12. Bloom filter是谁在什么时候发明的</h3><p>1970 <a href="https://en.wikipedia.org/w/index.php?title=Burton_Howard_Bloom&action=edit&redlink=1" target="_blank" rel="noopener">Burton Howard Bloom</a></p>
<h3 id="13-Bloom-filter-在Java、Python与Redis中的使用"><a href="#13-Bloom-filter-在Java、Python与Redis中的使用" class="headerlink" title="13. Bloom filter 在Java、Python与Redis中的使用"></a>13. Bloom filter 在Java、Python与Redis中的使用</h3><p><strong>Java</strong> </p>
<p>依赖库</p>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.google.guava<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>guava<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>29.0-jre<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>



<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> com.google.common.base.Charsets;</span><br><span class="line"><span class="keyword">import</span> com.google.common.hash.BloomFilter;</span><br><span class="line"><span class="keyword">import</span> com.google.common.hash.Funnels;</span><br><span class="line"><span class="keyword">import</span> org.apache.lucene.util.RamUsageEstimator;    </span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">myBF</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="comment">// public static &lt;T&gt; BloomFilter&lt;T&gt; create(Funnel&lt;? super T&gt; funnel, int expectedInsertions, double fpp) </span></span><br><span class="line">        BloomFilter&lt;String&gt; bf = BloomFilter.create(Funnels.stringFunnel(Charsets.UTF_8), <span class="number">100000</span>,<span class="number">0.000001</span>);</span><br><span class="line">        ArrayList&lt;String&gt; li = readInstallid(<span class="string">"/Users/dingzhenkai/Downloads/i10W.txt"</span>);</span><br><span class="line">        ArrayList&lt;String&gt; lin = readInstallid(<span class="string">"/Users/dingzhenkai/Downloads/i10WN.txt"</span>);</span><br><span class="line">        <span class="keyword">for</span>(String i: li)&#123;</span><br><span class="line">            <span class="comment">// 插入数据</span></span><br><span class="line">            bf.put(i);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">int</span> sp=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">int</span> sn=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">long</span> size = RamUsageEstimator.sizeOf(bf);</span><br><span class="line">        <span class="keyword">long</span> t1 = System.currentTimeMillis();</span><br><span class="line">        <span class="keyword">for</span>(String pi:li)&#123;</span><br><span class="line">            <span class="comment">// 查询数据是否在Bloom Filter里面</span></span><br><span class="line">            <span class="keyword">if</span>(bf.mightContain(pi)) sp++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(String ni: lin)&#123;</span><br><span class="line">            <span class="keyword">if</span>(!bf.mightContain(ni)) sn++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">long</span> t2 = System.currentTimeMillis();</span><br><span class="line">        System.out.println(<span class="string">"bloom filter size(byte): "</span>+ size);</span><br><span class="line">        System.out.println(<span class="string">"search 10W time(ms): "</span> + (t2-t1));</span><br><span class="line">        System.out.println(<span class="string">"10W pi true positive: "</span> + sp);</span><br><span class="line">        System.out.println(<span class="string">"10W ni true negative: "</span> + sn);</span><br><span class="line"></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p><strong>Python</strong></p>
<p>依赖库 <code>pip install pybloom</code>  <a href="https://github.com/jaybaird/python-bloomfilter" target="_blank" rel="noopener">github链接</a></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">from</span> pybloom <span class="keyword">import</span> BloomFilter</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>f = BloomFilter(capacity=<span class="number">1000</span>, error_rate=<span class="number">0.001</span>) <span class="comment"># 用 capacity与error_rate 构建Bloom Filter</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>[f.add(x) <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">10</span>)] <span class="comment"># add(x) 如果x不在f里面，返回False；如果在，返回True</span></span><br><span class="line">[<span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>, <span class="literal">False</span>]</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>all([(x <span class="keyword">in</span> f) <span class="keyword">for</span> x <span class="keyword">in</span> range(<span class="number">10</span>)])</span><br><span class="line"><span class="literal">True</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">10</span> <span class="keyword">in</span> f</span><br><span class="line"><span class="literal">False</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="number">5</span> <span class="keyword">in</span> f</span><br><span class="line"><span class="literal">True</span></span><br></pre></td></tr></table></figure>

<p><strong>Redis</strong></p>
<p>依赖module <a href="https://github.com/RedisBloom/RedisBloom" target="_blank" rel="noopener">RedisBloom</a></p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">docker pull redislabs/rebloom:2.2.4</span><br><span class="line">zkding:~ dingzhenkai$ docker run -p 6379:6379 -d --name redis-redisbloom redislabs/rebloom:2.2.4</span><br><span class="line">c6da2b5ee65f3ce8372f5f9cfdaf359452006577a0f1ce3ce4f748100f39991f</span><br><span class="line">zkding:~ dingzhenkai$ docker exec -it redis-redisbloom bash</span><br><span class="line">root@c6da2b5ee65f:/data# redis-cli  </span><br><span class="line">BF.RESERVE &#123;key&#125; &#123;error_rate&#125; &#123;capacity&#125; [EXPANSION expansion] [NONSCALING]</span><br><span class="line">127.0.0.1:6379&gt; BF.ADD mybloomfilter foo  </span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; BF.ADD mybloomfilter bar</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; BF.ADD mybloomfilter lue</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; BF.EXISTS mybloomfilter foo</span><br><span class="line">(integer) 1</span><br><span class="line">127.0.0.1:6379&gt; BF.EXISTS mybloomfilter fuc</span><br><span class="line">(integer) 0</span><br></pre></td></tr></table></figure>














      
      <!-- 打赏 -->
      
    </div>
    <footer class="article-footer">
      <a data-url="https://zkdingme.github.io/2020/08/18/bloom-filter-kiss/" data-id="ckse3iv0r002soqj5bua6dmd6"
        class="article-share-link">分享</a>
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/bloom-filter/" rel="tag">bloom filter</a></li></ul>

    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-ChinaJoy2020" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/08/03/ChinaJoy2020/"
    >ChinaJoy2020</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/08/03/ChinaJoy2020/" class="article-date">
  <time datetime="2020-08-03T08:26:32.000Z" itemprop="datePublished">2020-08-03</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E4%BC%9A%E8%AE%AE/">会议</a>
  </div>

      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>2020年7月31号，我与朋友逛了ChinaJoy，从11点到17点，6个小时，看了以8k高清为卖点的终端显示设备(电视、LED大屏幕、车载显示)、各家推出的以畅玩游戏和支持云游戏为卖点的手机(oppo游戏机，红魔游戏机等)、各家以coser和showgirl为卖点的游戏等。总结来说，这是我第一次去漫展，我原以为会有大量秀色可餐的妹子，但其实没有，大多showgirl身材和脸较为一般，不是从漫画中走出来的，令人失望。之后应该不会因为妹子再去漫展了，我还不如在食堂看妹子，至少交大的女孩们腹有诗书气自华，赏心悦目。不过这次漫展我还是有收获的，我试玩了许多游戏机(手机)，了解到当前游戏机的安全配置，对我们secsense数据收集有影响的配置，下面我就详细说一下。</p>
<h2 id="需要关注的当前手机的安全与隐私配置"><a href="#需要关注的当前手机的安全与隐私配置" class="headerlink" title="需要关注的当前手机的安全与隐私配置"></a>需要关注的当前手机的安全与隐私配置</h2><h3 id="可以收集的新数据"><a href="#可以收集的新数据" class="headerlink" title="可以收集的新数据"></a>可以收集的新数据</h3><p>Android Q之后限制获取IMEI、device id等，<a href="http://www.msa-alliance.cn/" target="_blank" rel="noopener">移动安全联盟MSA</a> 推出一个SDK可以收集IMEI的替代数据：</p>
<table>
<thead>
<tr>
<th>英文缩写</th>
<th>中文名称</th>
<th>英文全称</th>
<th>长度</th>
</tr>
</thead>
<tbody><tr>
<td>IMEI</td>
<td>国际移动设备识别码</td>
<td>International Mobile Equipment Identity</td>
<td>15~17位</td>
</tr>
<tr>
<td>UDID</td>
<td>设备唯一标识符</td>
<td>Unique Device Identifier</td>
<td>最长64位</td>
</tr>
<tr>
<td>OAID</td>
<td>匿名设备标识符</td>
<td>Open Anonymous Device Identifier</td>
<td>最长64位</td>
</tr>
<tr>
<td>VAID</td>
<td>开发者匿名设备标识符</td>
<td>Vender Anonymous Device Identifier</td>
<td>最长64位</td>
</tr>
<tr>
<td>AAID</td>
<td>应用匿名设备标识符</td>
<td>Application Anonymous Device Identifier</td>
<td>最长64位</td>
</tr>
</tbody></table>
<p><strong>注意这些数据不是固定的，用户可以在设置界面重置。</strong></p>
<h3 id="收集到的数据可能是假的"><a href="#收集到的数据可能是假的" class="headerlink" title="收集到的数据可能是假的"></a>收集到的数据可能是假的</h3><p>手机提供隐私保护措施，可能会提供假数据给我们的数据收集SDK。Secsense需要关注的假数据分为两类，一类是脚本小子类的，坏人伪造假数据；另一类就是手机的隐私保护措施提供的假数据。前者需要杀，后者不能杀。我们需要关注以下问题：</p>
<ul>
<li>哪些手机型号可以提供假数据，提供了哪些假数据<strong>（需要维护一个数据库）</strong><br>我观察到的有定位数据、设备标识符等</li>
<li>如何区分脚本小子的假数据和手机隐私保护措施的假数据</li>
</ul>
<h3 id="手机自带安全检测功能-可以利用，不要冲突"><a href="#手机自带安全检测功能-可以利用，不要冲突" class="headerlink" title="手机自带安全检测功能(可以利用，不要冲突)"></a>手机自带安全检测功能(可以利用，不要冲突)</h3><p>现在手机都自带一些安全检测功能，Secsense需要注意与这些功能不要冲突，可以利用这些现有的检测功能做一些事情。</p>
<p>我观察到的有检测root、检测usb是否连接、检测虚假wlan、wlan被arp攻击、wlan被dns服务器劫持、wlan加密、验证码安全、恶意应用等、截屏录屏、后台录音拍照、危险权限使用统计等</p>
<p>我们需要关注以下问题：</p>
<ul>
<li>哪些手机提供了哪些安全检测功能，最好维护这样一个数据库</li>
<li>哪些功能我们可以利用，用来干嘛</li>
</ul>
<h3 id="手机性能越来越好了"><a href="#手机性能越来越好了" class="headerlink" title="手机性能越来越好了"></a>手机性能越来越好了</h3><p>cpu 8核，内存与存储都很大，移动云计算大有可为</p>

      
      <!-- 打赏 -->
      
    </div>
    <footer class="article-footer">
      <a data-url="https://zkdingme.github.io/2020/08/03/ChinaJoy2020/" data-id="ckse3iuz8000boqj5d06c2trx"
        class="article-share-link">分享</a>
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ChinaJoy2020/" rel="tag">ChinaJoy2020</a></li></ul>

    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-ADS-Notes" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/06/23/ADS-Notes/"
    >ADS_Notes</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/06/23/ADS-Notes/" class="article-date">
  <time datetime="2020-06-23T05:45:55.000Z" itemprop="datePublished">2020-06-23</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E8%AF%BE%E7%A8%8B%E7%AC%94%E8%AE%B0/">课程笔记</a>
  </div>

      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <p>一些知识点，概念，问题以及解决方案</p>
<h2 id="Let-1"><a href="#Let-1" class="headerlink" title="Let 1"></a>Let 1</h2><h3 id="为什么cpu频率不能一直增加："><a href="#为什么cpu频率不能一直增加：" class="headerlink" title="为什么cpu频率不能一直增加："></a>为什么cpu频率不能一直增加：</h3><ul>
<li>频率越高，耗能越好，热量越多，不好散热</li>
<li>信号传播限制。cpu大概1cm长，信号从一头传到另一头也需要时间，所以不能无限变快</li>
</ul>
<h3 id="什么是NUMA："><a href="#什么是NUMA：" class="headerlink" title="什么是NUMA："></a>什么是NUMA：</h3><p>随着科学计算、事务处理对计算机性能要求的不断提高，SMP（对称多处理器）系统的应用越来越广泛，规模也越来越大，但由于传统的SMP系统中，所有处理器都共享系统总线，因此当处理器的数目增大时，系统总线的竞争冲突加大，系统总线将成为瓶颈，所以目前SMP系统的CPU数目一般只有数十个，可扩展能力受到极大限制。NUMA技术有效结合了SMP系统易编程性和MPP（大规模并行）系统易扩展性的特点，较好解决了SMP系统的可扩展性问题，已成为当今高性能服务器的主流体系结构之一。</p>
<p><strong>非统一内存访问架构</strong>（英语：<strong>Non-uniform memory access</strong>，简称NUMA）是一种为<a href="https://zh.wikipedia.org/wiki/多處理器" target="_blank" rel="noopener">多处理器</a>的电脑设计的内存架构，内存访问时间取决于内存相对于处理器的位置。在NUMA下，处理器访问它自己的本地内存的速度比非本地内存（内存位于另一个处理器，或者是处理器之间共享的内存）快一些。</p>
<p><a href="https://zhuanlan.zhihu.com/p/33621500" target="_blank" rel="noopener">深挖NUMA</a></p>
<h3 id="并行与并发的区别"><a href="#并行与并发的区别" class="headerlink" title="并行与并发的区别"></a>并行与并发的区别</h3><p><strong>并行(parallel)</strong>：指在同一时刻，有多条指令在多个处理器上同时执行。就好像两个人各拿一把铁锨在挖坑，一小时后，每人一个大坑。所以无论从微观还是从宏观来看，二者都是一起执行的。</p>
<p><img src="https://segmentfault.com/img/bV1GiB?w=449&h=192" alt="图片描述"><br><strong>并发(concurrency)</strong>：指在同一时刻只能有一条指令执行，但多个进程指令被快速的轮换执行，使得在宏观上具有多个进程同时执行的效果，但在微观上并不是同时执行的，只是把时间分成若干段，使多个进程快速交替的执行。这就好像两个人用同一把铁锨，轮流挖坑，一小时后，两个人各挖一个小一点的坑，要想挖两个大一点得坑，一定会用两个小时。</p>
<p><img src="https://segmentfault.com/img/bV1GiJ?w=449&h=192" alt="图片描述"></p>
<h3 id="给并行与分布式系统分类"><a href="#给并行与分布式系统分类" class="headerlink" title="给并行与分布式系统分类"></a>给并行与分布式系统分类</h3><p>SISD</p>
<p><img src="https://pic2.zhimg.com/80/v2-195580bb521e48584bdb7564fdab7c8d_1440w.png" alt="img"></p>
<p><strong>单指令流单数据流</strong>（<a href="https://zh.wikipedia.org/wiki/英文" target="_blank" rel="noopener">英文</a>：Single instruction, single data，<a href="https://zh.wikipedia.org/wiki/縮寫" target="_blank" rel="noopener">缩写</a>：<strong>SISD</strong>），每个指令部件每次仅译码一条指令，而且在执行时仅为操作部件提供一份数据。符合<a href="https://zh.wikipedia.org/wiki/冯·诺伊曼结构" target="_blank" rel="noopener">冯·诺伊曼结构</a>。</p>
<p>单指令流单数据流是<a href="https://zh.wikipedia.org/wiki/費林分類法" target="_blank" rel="noopener">费林分类法</a>中4种计算机处理架构类别的一种。在这个分类系统中，分类根据是<a href="https://zh.wikipedia.org/wiki/指令" target="_blank" rel="noopener">指令</a>流和<a href="https://zh.wikipedia.org/wiki/資料" target="_blank" rel="noopener">资料</a>流的数量，以此根据来划分计算机处理架构的类别。根据<a href="https://zh.wikipedia.org/w/index.php?title=米高·J·費林&action=edit&redlink=1" target="_blank" rel="noopener">米高·J·费林</a>的观点，当指令、资料处理流水化/管线化时，单指令流单数据流也可以拥有<a href="https://zh.wikipedia.org/wiki/並行計算" target="_blank" rel="noopener">并行计算</a>的特点。<a href="https://zh.wikipedia.org/wiki/指令管線化" target="_blank" rel="noopener">管线化的指令读取执行</a>在当代的单指令流单数据流处理机种上很常见。<a href="https://zh.wikipedia.org/wiki/單指令流單數據流#cite_note-1" target="_blank" rel="noopener">[1]</a><a href="https://zh.wikipedia.org/wiki/單指令流單數據流#cite_note-2" target="_blank" rel="noopener">[2]</a></p>
<p>SIMD</p>
<p><strong>单指令流多数据流</strong>（英语：<strong>Single Instruction Multiple Data</strong>，<a href="https://zh.wikipedia.org/wiki/縮寫" target="_blank" rel="noopener">缩写</a>：<strong>SIMD</strong>）是一种采用一个<a href="https://zh.wikipedia.org/wiki/控制器" target="_blank" rel="noopener">控制器</a>来控制多个<a href="https://zh.wikipedia.org/wiki/处理器" target="_blank" rel="noopener">处理器</a>，同时对一组数据（又称“<a href="https://zh.wikipedia.org/w/index.php?title=数据向量&action=edit&redlink=1" target="_blank" rel="noopener">数据向量</a>”）中的每一个分别执行<strong>相同</strong>的操作从而实现空间上的<a href="https://zh.wikipedia.org/wiki/并行" target="_blank" rel="noopener">并行</a>性的技术。</p>
<p>在<a href="https://zh.wikipedia.org/wiki/微处理器" target="_blank" rel="noopener">微处理器</a>中，单指令流多数据流技术则是一个<a href="https://zh.wikipedia.org/wiki/控制器" target="_blank" rel="noopener">控制器</a>控制多个平行的<a href="https://zh.wikipedia.org/w/index.php?title=处理微元&action=edit&redlink=1" target="_blank" rel="noopener">处理微元</a>，例如<a href="https://zh.wikipedia.org/wiki/Intel" target="_blank" rel="noopener">Intel</a>的<a href="https://zh.wikipedia.org/wiki/MMX" target="_blank" rel="noopener">MMX</a>或<a href="https://zh.wikipedia.org/wiki/SSE" target="_blank" rel="noopener">SSE</a>，以及<a href="https://zh.wikipedia.org/wiki/AMD" target="_blank" rel="noopener">AMD</a>的<a href="https://zh.wikipedia.org/wiki/3D_Now!" target="_blank" rel="noopener">3D Now!</a>指令集。</p>
<p><a href="https://zh.wikipedia.org/wiki/圖形處理器" target="_blank" rel="noopener">图形处理器</a>（GPU）拥有强大的并发处理能力和可编程流水线，面对单指令流多数据流时，运算能力远超传统CPU。<a href="https://zh.wikipedia.org/wiki/OpenCL" target="_blank" rel="noopener">OpenCL</a>和<a href="https://zh.wikipedia.org/wiki/CUDA" target="_blank" rel="noopener">CUDA</a>分别是目前最广泛使用的开源和专利<a href="https://zh.wikipedia.org/wiki/通用圖形處理器" target="_blank" rel="noopener">通用图形处理器</a>（GPGPU）运算语言。</p>
<p><img src="https://pic4.zhimg.com/v2-9c786a3bf86c115a7b786a3d1f03e24c_1440w.jpg" alt="SIMD简介"></p>
<p><img src="https://pic4.zhimg.com/80/v2-0c56ad7326f03b91fbf48bd0ce5f03ef_1440w.jpg" alt="img">标量运算与SIMD运算对比</p>
<p>如上图所示，使用标量运算一次只能对一对数据执行乘法操作，而采用SIMD乘法指令，则一次可以对四对数据同时执行乘法操作。</p>
<p>MISD</p>
<p><img src="https://pic3.zhimg.com/80/v2-e99d2bf9b745bd5255df7f14cd065ae6_1440w.png" alt="img"></p>
<p>MISD是采用多个指令流来处理单个数据流。由于实际情况中，采用多指令流处理多数据流才是更有效的方法，因此MISD只是作为理论模型出现，没有投入到实际应用之中。</p>
<p>MIMD</p>
<p>多指令流多数据流机器（MIMD）</p>
<p><img src="https://pic3.zhimg.com/80/v2-c57263ddd437016913f8916ec1b3e042_1440w.png" alt="img"></p>
<p>MIMD机器可以同时执行多个指令流，这些指令流分别对不同数据流进行操作。最新的多核计算平台就属于MIMD的范畴，例如Intel和AMD的双核处理器等都属于MIMD。</p>
<h3 id="Cache写机制，write-through-与-write-back"><a href="#Cache写机制，write-through-与-write-back" class="headerlink" title="Cache写机制，write through 与 write back"></a>Cache写机制，write through 与 write back</h3><p>Write-through（直写模式）在数据更新时，同时写入缓存Cache和后端存储。此模式的优点是操作简单；缺点是因为数据修改需要同时写入存储，数据写入速度较慢。</p>
<p>Write-back（回写模式）在数据更新时只写入缓存Cache。只在数据被替换出缓存时，被修改的缓存数据才会被写到后端存储。此模式的优点是数据写入速度快，因为不需要写存储；缺点是一旦更新后的数据未被写入存储时出现系统掉电的情况，数据将无法找回。</p>
<h3 id="snoopy-cache"><a href="#snoopy-cache" class="headerlink" title="snoopy cache"></a>snoopy cache</h3><p>In order to prevent this and maintain <a href="https://en.wikipedia.org/wiki/Cache_coherence" target="_blank" rel="noopener">cache coherence</a>, snoopy caches monitor (‘snoop on’) the memory bus to detect any writes to values that they are holding, including changes coming from other processors or distributed computers.</p>
<p>However, this approach can only work in computer architectures like <a href="https://en.wikipedia.org/wiki/SGI_Challenge" target="_blank" rel="noopener">SGI Challenge</a> and <a href="https://en.wikipedia.org/wiki/SGI_Onyx" target="_blank" rel="noopener">SGI Onyx</a> where a single memory bus is shared between all processors.</p>
<h3 id="CPU-三大架构-SMP-NUMA-MPP"><a href="#CPU-三大架构-SMP-NUMA-MPP" class="headerlink" title="CPU 三大架构 SMP NUMA MPP"></a>CPU 三大架构 SMP NUMA MPP</h3><h4 id="smp"><a href="#smp" class="headerlink" title="smp"></a>smp</h4><p>SMP （Symmetric Multiprocessing） , 对称多处理器. 顾名思义, 在SMP中所有的处理器都是对等的, 它们通过总线连接共享同一块物理内存，这也就导致了系统中所有资源(CPU、内存、I/O等)都是共享的，当我们打开服务器的背板盖，如果发现有多个cpu的槽位，但是却连接到同一个内存插槽的位置，那一般就是smp架构的服务器，日常中常见的pc啊，笔记本啊，手机还有一些老的服务器都是这个架构，其架构简单，但是拓展性能非常差，从linux 上也能看到:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ls /sys/devices/system/node/<span class="comment"># 如果只看到一个node0 那就是smp架构</span></span><br></pre></td></tr></table></figure>

<p>可以看到只有仅仅一个node，经过大神们的测试发现，2至4个CPU比较适合smp架构。</p>
<h4 id="NUMA"><a href="#NUMA" class="headerlink" title="NUMA"></a>NUMA</h4><p>NUMA （ Non-Uniform Memory Access），非均匀访问存储模型，这种模型的是为了解决smp扩容性很差而提出的技术方案，如果说smp 相当于多个cpu 连接一个内存池导致请求经常发生冲突的话，numa 就是将cpu的资源分开，以node 为单位进行切割，每个node 里有着独有的core ，memory 等资源，这也就导致了cpu在性能使用上的提升，但是同样存在问题就是2个node 之间的资源交互非常慢，当cpu增多的情况下，性能提升的幅度并不是很高。所以可以看到很多明明有很多core的服务器却只有2个node区。</p>
<p><img src="http://abcdxyzk.github.io/images/kernel/2015-06-02-13.png" alt="img"></p>
<h4 id="MPP"><a href="#MPP" class="headerlink" title="MPP"></a>MPP</h4><p>MPP (Massive Parallel Processing) ，这个其实可以理解为刀片服务器，每个刀扇里的都是一台独立的smp架构服务器，且每个刀扇之间均有高性能的网络设备进行交互，保证了smp服务器之间的数据传输性能。相比numa 来说更适合大规模的计算，唯一不足的是，当其中的smp 节点增多的情况下，与之对应的计算管理系统也需要相对应的提高。</p>
<h2 id="Let-2-consistency"><a href="#Let-2-consistency" class="headerlink" title="Let 2 consistency"></a>Let 2 consistency</h2><p><strong>一致性</strong>:定义了更新出现顺序和可见性的规则,伴随着tradeoff.<br><strong>在分布式中困难原因</strong>:数据复制(cache)、并发(无共享锁)、failure(机器或网络)<br>. <strong>Strict consistency</strong>: 读到最新写的数据；同个CPU所有操作的timestamp即为执行顺序. <strong>Sequentialconsistency</strong>：最接近Strict consistency,只是将total order代替timestamp.<br><strong>SC要求</strong>：单个处理器内部操作有顺序；对同一个内存地址的访问遵循FIFO.<br><strong>IVY</strong>：<strong>MOTIVATION</strong>: 原始DSM无法保障SC；shared memory便于写并行程序,避免使用message passing.<br><strong>Centralizedmanager</strong>: read/write operation order.<br><strong>SC缺点</strong>：必须有全局控制机制；必须有内存同步操作,造成伪共享.<br><strong>RC</strong>:引入lock(同步变量), acquire() 和release() 是SC,可产生和SC相同结果.<br><strong>SC&amp;RC区别</strong>：SC中,看到相同读写顺序；RC中,以放锁顺序看到写结果.<br><strong>同步机制</strong>：update-base(eager RC),放锁时对all发modification,在拿锁的时候不需要同步操作; invalidated-based(lazy RC), 放锁时发invalidations,需要时取,可避免不必要的msg发送,可能有较大的access miss开销.<br><strong>write protoco</strong>l: 修改之前创建一个twin,放锁时通过比较产生diff.允许multiple write,消除了伪共享；节省网络发送开销.<br><strong>LRC</strong>：满足happened-before关系即可,order是应用在process interval(即一个拿放锁)上的,SC是在每个opt；<br><strong>happened-before interva</strong>l: 若间隔i在j之前,则i内所有操作在j之前<br><strong>Lamport timestamps</strong>:用来在分布式系统中决定事件顺序. 1.事件开始之前,process的计数器先+1；2.发msg时,将计数器也发送；3.接受者先将自己的计数器设置为发送方和自己计数器的最大值,再接受msg.<br><strong>SC&amp;RC缺点</strong>：慢,每次操作之前都要询问master/lock server;对参与者available要求高,要求所有成员都在.</p>
<h2 id="Let-3-eventual-consistency"><a href="#Let-3-eventual-consistency" class="headerlink" title="Let 3 eventual consistency"></a>Let 3 eventual consistency</h2><p><strong>EC:</strong> 保证最终状态convergence,选择性提供因果性保证.<br><strong>EC&amp;SC</strong>:写冲突较少；先update,再考虑是否可以serialized.<br><strong>Bayou</strong>:实现了availability(A), 低延时(L),容忍partition(P),causal+性.<br><strong>Anomalies</strong>:<strong>write-write conflict</strong>à保证状态最终convergence,即将write作为update<br>function,利用update ID&lt;time T,node ID&gt;来决定不同节点的更新顺序（X &lt; Y iff [(X.T &lt;<br>Y.T) or(X.T=Y.T and X.ID &lt; Y.ID)]）.总之,先更新,若有不一致,则rollback,同步update<br>set,replay更新函数；<br><strong>stale read</strong>à即不同node本地时钟不一致,则根据相应的updateID做出的操作顺序可能出错,采用lamport logical clock来保证因果关系；<br><strong>Tentative to show result</strong>àde-centralized:如果发现每个node的时间戳都大于N,则N之前的update都是稳定的；但是,如果有一个node离线,则没有update可以stable了.centralized:有一个server是primary,对update分配CSN（Cmt-Seq-No）,分配了的update即为stable的；但是,CSN大多数情况和tentative顺序匹配,因为server按逻辑顺序发,但是不是总是匹配的,primary可能先看到较新的update,进而分配小的CSN.总之还是倾向于central.<br><strong>COPS</strong>:在Bayou基础上,实现了可扩展(S),因为Bayou基于时间戳,不scalable.<br><strong>Causality的三种来源</strong>：Thread-of-Execution（同一个线程内部opt顺序）、Get-from（op2读到op1写的值）、Transitivity.<br><strong>Causal+</strong>：因果性+冲突处理.<br><strong>MOTIVATION</strong>: 之前系统实现causal+是Log-exchange based,限制了可扩展性,没有cross-site的因果保证.<br><strong>KEY to Scalability</strong>:metadata的依赖关系隐含了因果性,用分布式的verification代替单个的serialization,即当replication的依赖关系都满足时,才CMT.<br><strong>接口</strong>：getà无区别；put_after(key,value,deps)àclient library存储数据依赖关系deps,向site发送数据副本时附带deps,当site确保deps都被满足之后才CMT.</p>
<h2 id="let-4-crash-recovering"><a href="#let-4-crash-recovering" class="headerlink" title="let 4 crash recovering"></a>let 4 crash recovering</h2><p>(focus单机failure)一个tx内部的原子性：DO-REDO-UNDO协议.<br><strong>解决failure</strong>：Straw Manàcopy on write,但是当多个trans共享文件时,无法保障logging.<br><strong>SYSR</strong>：<strong>Log结构</strong>：append-only,减少随机访问；反向链表,后面log指向前一个log位置,保证只有append操作.<br><strong>Log规则</strong>：Write Ahead Log (WAL)协议；trans在CMT的时候,在log上append一个cmt记录<br><strong>Recovery</strong>:从后向前扫log,abort掉没有CMT标记的log,从前到后REDO已经CMT的log.<br><strong>Checkpoint**</strong>原因<strong>：避免abort掉长的trans；避免从空白状态开始recover.<br>**How to CKPT</strong>: 1.当前无action进行, 2.在log里写一个CKPT记录,包含正在进行的所有trans及指针指向其最近的log,方便undo,3.保存所有文件,dirty cacheàdisk, 4.原子地用新CKPT代替旧CKPT.<br><strong>Log类型</strong>：一般REDO&amp;UNDO都支持,UNDOà长的trans可能被abort,而REDOà对于最终CMT的长trans,CKPT可能只记录了一部分；REDO-only和UNDO-only形式也可以.<br><strong>FSD</strong>：<strong>logging File System</strong>:因为同步写很慢,有对同一个位置的冗余写,恢复需要扫整个FS；Write-back Cache,即只写回cache,cache满了之后flush,可以batch降低I/O,但是由于刷回disk顺序不确定,在crash时爆炸,甚至无法保证metadata的原子性；因此FS采用REDO-only<br>log+CKPT,只针对metadata(短trans).<br><strong>WAL+CKPT+REDO</strong>:<strong>写操作</strong>：在cache中修改,appendREDO log.<br><strong>When flush dirty data</strong>: CMT log到disk之后.<br><strong>Log Structure</strong>: 环状的disk文件,通过同步写来append新log；内存中的log是group<br>cmt到disk中的,牺牲了一定的数据稳定性,降低了I/O；通过做CKPT,定期clean.<br><strong>Recovery</strong>:从CKPT开始扫log,找到CMT的；从CKPT开始replay</p>
<h2 id="let-5-concurrency-control"><a href="#let-5-concurrency-control" class="headerlink" title="let 5 concurrency control"></a>let 5 concurrency control</h2><p>多个tx的可串行性. <strong>Serializability</strong>:<br>等价于某种串行执行；等价即为操作相同,处理冲突方法相同；冲突即为多个操作同时访问相同数据,至少有一个为写. <strong>2PL(lock-based)</strong>:</p>
<ol>
<li><p>Growing:tx拿锁,整个tx时期. </p>
</li>
<li><p>2.Shrinking:放锁, cmt期间.</p>
</li>
</ol>
<p><strong>死锁</strong>:1.顺序拿锁;开销大; 2.timeout检测,abort自己;要有redo/undo log支持.</p>
<p><strong>缺点</strong>:1.需要分布式死锁检测;2.对大量只读的场景不友好（全是只读就不需要锁）可能block更新.</p>
<p><strong>异常</strong>:p1.脏读,读到最终uncmt的中间数据.p2.不可重复读,数据读之后,被修改或者删除,then cmt.p3.幻读.读数据之后,符合条件的数据被增加. **Isolation</p>
<p>  Level(IL)<strong>: Read uncommitted(p123); Read committed(p23); Repeatable<br>  read(p3); Anomaly serialable. **Snapshot<br>  Isolation(SI)</strong>:<strong>背景</strong>: 原来依据异常划分IL,含混不清,粒度粗;<strong>思想</strong>:无锁;每个数据有多个version;消除p12;适用于大量只读tx. <strong>流程</strong>: 1.开始前有时间戳T.sts;2.读满足x(i).cts&lt;=T.sts的最新x(i);3.buffer写,添加数据到T.wset中;4.预分配cmt时间戳T.cts,确认T.wset内数据无更新,则cmt;若T.sts&lt; x.cts&lt;T.cts,则abort. (即解决w-w冲突)<strong>优点</strong>:无锁开销小;只读tx不会阻塞;<strong>缺点</strong>:不是serialable</p>
<p><strong>2PL</strong>：在2PL协议下，每个transaction都会经过两个阶段：在第一个阶段里，transaction根据需要不断地获取锁，叫做 <strong>growing phase (expanding phase)</strong>；在第二个阶段里，transaction开始释放其持有的锁，根据2PL的规则，这个transaction不能再获得新的锁，所以它所持有的锁逐渐减少，叫做 <strong>shrinking phase (contracting phase)</strong>。</p>
<p><strong>Snapshot Isolation</strong>：</p>
<p>事务在启动时得到一个数据库的版本号。事务结束时，成功提交仅当它修改的快照的数据项此时没有被外界改变，即没有<a href="https://zh.wikipedia.org/w/index.php?title=%E5%86%99-%E5%86%99%E5%86%B2%E7%AA%81&action=edit&redlink=1" target="_blank" rel="noopener">写-写冲突</a>，否则事务流产（abort）。</p>
<h4 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h4><p>文章主要是抨击了原有的基于异常（anomaly）来定义隔离级别（isolation level）的这种方法，原有的划分方法说明是含混不清的，粒度也是不够细的。作者分析了当年流行的isolation levels（后面缩写IL）后，提出了一种新的mutiversionisolation——snapshot isolation。ps.论文比较老（SIGMOD95），有些名词比较生僻。</p>
<h4 id="ANSI-IL和三种异常"><a href="#ANSI-IL和三种异常" class="headerlink" title="ANSI IL和三种异常"></a>ANSI IL和三种异常</h4><p><strong>P1: Dirty Read</strong>：T1改了某个数据项，T2在T1 commit之前读到，然而T1并没有commit，所以T2觉得自己一定读了一个假的数据项</p>
<p><strong>P2: Unrepeatable**</strong>（<strong><strong>Fuzzy</strong></strong>）<strong>**Read</strong>：同样是T2，读完一个数据后，这个数据被T1修改或者删除了，然后T1commit了，然而T2再想读取该数据，却不能够了。</p>
<p><strong>P3:Phantome**</strong>（幽灵）**：T1根绝某种查找策略先读到一些数据，T2开始执行，产生一些符合该搜索策略的data，T1再次执行时，发现与第一次查找的数据不一致。</p>
<p>这三种异常<strong>都不会在**</strong>serial**的情况下出现。</p>
<p><strong>为什么说定义含混？</strong></p>
<p>拿定义P1来说，这一句话可以理解为以下两种情况：（abort or commit 1表示 a1 or c1）</p>
<ol>
<li><p>w1[x]… …r2[x]… … (a1 and c2 in either order),</p>
</li>
<li><p>w1[x]… …r2[x]… … ((c1 or a1) and (c2 or a2) ineither order)因为定义中并没有坚持说T1 abort了</p>
</li>
</ol>
<p>可见2对于P1的理解，明显比1要looser，这样理解意味着允许的异常比1要多。所以不严格。</p>
<p>ANSI定义的四种隔离级别就是根据这三种异常定义的：</p>
<table>
<thead>
<tr>
<th>Isolation level</th>
<th>P1</th>
<th>P2</th>
<th>P3</th>
</tr>
</thead>
<tbody><tr>
<td>Read uncommitted</td>
<td>Possible</td>
<td>Possible</td>
<td>Possible</td>
</tr>
<tr>
<td>Read committed</td>
<td>Impossible</td>
<td>Possible</td>
<td>Possible</td>
</tr>
<tr>
<td>Repeatable read</td>
<td>Impossible</td>
<td>Impossible</td>
<td>Possible</td>
</tr>
<tr>
<td>Anomaly serialable</td>
<td>Impossible</td>
<td>Impossible</td>
<td>Impossible</td>
</tr>
</tbody></table>
<h4 id="其他的隔离方法"><a href="#其他的隔离方法" class="headerlink" title="其他的隔离方法"></a>其他的隔离方法</h4><p><strong>cursor isolation</strong>：</p>
<p>主要用在SQL数据库中，为了解决<strong>lost- update-anomaly</strong>：比如说T2即使commit了，它的更新缺丢失了。举例：</p>
<p>P4: r1[x]…w2[x]…w1[x]…c1</p>
<p>这样子，x的最终值是T1修改的值，T2的wirte操作如同丢失一般。</p>
<p>数据库中，游标（cursor）实际上是一种能从包括多条数据记录的结果集中每次提取一条记录的机制。在这里，其实是利用这种方法，结合读写锁操作，T1读到某个item时，执行上锁，直到它commit，再放锁，保证cursor知道的记录在T1 commit之前不会被其他T2读到并修改，也就不会让T2感到自己的更新丢失。</p>
<p>很明显，这个方法并不通用，也不方便。</p>
<p>下面着重讲一下论文提出的snapshot isolation，也就是基于快照的隔离</p>
<h4 id="snapshot-isolation（SI）"><a href="#snapshot-isolation（SI）" class="headerlink" title="snapshot isolation（SI）"></a>snapshot isolation（SI）</h4><p>属于多版本并发控制（multiversion concurrencycontrol）的一种</p>
<ol>
<li><p>写在一个带锁的缓冲区</p>
</li>
<li><p>读来自“snapshot”</p>
</li>
<li><p>只有当<strong>没有**</strong>write-writeconflict**时候，才会提交commit</p>
</li>
</ol>
<p>详细说明如下：</p>
<p>一个transaction T1会在snapshot中读取数据，并获得一个时间戳start-timestamp，这个时间戳可以是该transaction读取数据前的任何时间。在执行过程中commit之前，T1的更新操作对其他transaction 是不可兼得当T1要commit时，会获得一个commit-timestamp，大于已有的所有sts和cts，T1要想成功commit，就要保证在T1.sts—T1.cts之间，没有其他transaction commit并且该transaction修改过T1修改过的数据（write-write conflict），若有，则T1 abort掉。这个特点称作“<strong>First commit wins</strong>”。</p>
<p>当T1成功commit后，它的更新操作会对其他sts大于T1cts的transactions可见。</p>
<p><strong>值得注意的是**</strong>SI<strong><strong>并不是</strong></strong>serialable<strong>**的</strong>。考虑以下情况：</p>
<p>Begin: x=y=50</p>
<p>T1 read x=50, write y = 40;</p>
<p>T2 read y = 50, write x = 40;</p>
<p>Commit T1,T2.</p>
<p>两者并没有write-write conflict，所以可以成功commit，这就引发了异常“short fork”，即中间有一段状态在T1T看来并不是一致的，直到两者都commit后，所有状态才又保持一致。这种异常在serialability中就不会出现。</p>
<p><strong>SI**</strong>的优点**：</p>
<p>SI surely can be benefit to read-only and short-running updatetransition, because it never block read-only transition and readers do notblock updates.</p>
<p>避免了传统保证一致性时使用锁的开销，使得只读transaction不会阻塞reader transaction.</p>
<h2 id="let-6-2pc"><a href="#let-6-2pc" class="headerlink" title="let 6 2pc"></a>let 6 2pc</h2><p>在分布式系统中保证多个tx的原子性和并发能力.<br><strong>2PC</strong>:<strong>流程</strong>：1. Voting. 每个参与者准备cmt,若可以,则上锁,并将投票结果写在Permanent Storage(PS)上,之后返回投票；2. Committing. TC(transaction coordinator)收集所有投票,记录在PS上,并将结果广播给参与者,参与者实际执行cmt或者abort.<br><strong>Time Out</strong>: 在cmt阶段,time out on TC, 则投cmt的参与者需要执行termination协议（发送msg给别的参与者请求信息,可以解决除TC挂掉之外的大部分failure）<br><strong>Crash &amp; Reboot</strong>: TC和参与者都根据log信息来决定自己的操作,如果参与者在log中发现了cmt信息,则需要执行termination协议来决定；failure后恢复时间长（需要发msg）<br><strong>并发控制和2PC</strong>：参与者对读写使用2PL/SI,用2PC进行cmt.<br><strong>Sinfonia:</strong> 共享数据存储服务；横跨多个server；地址空间划分；保证一致性的复制. <strong>Motivation:</strong><br>传统的分布式设计是基于message-passing,需要有复杂的协议来处理；Sinfonia可以使host以一种容错,可扩展,一致的方式共享应用数据,且无需考虑复杂协议.<br>2pc需要多轮网络交互，开销较大<br><strong>Mini-transaction**</strong>背景<strong>: 传统2PC情况下, TC先执行一个transaction,这需要让participants执行一到多次transactions（读取或修改数据项）,在这次transaction结束后,TC执行2PC；在Sinfonia中,TC在application node,而participants在memory node中；如果一次transaction的行为不会影响到TC的决定的话,TC其实可以直接将这些操作放在2PC的第一个phase中执行（piggyback）,从而减少了一次round-trip 沟通所花费的时间；piggyback条件：最后一次action不会影响TC关于abort 或者commit的决定,最后一次action对TC的影响,participant已经知道.</strong>Mini-tx<strong>**语义</strong>：cmp, read, write. 1.用cmp检查数据. 2.若全部匹配,则用read取数据/用write修改. 3.否则abort. <strong>优点</strong>：提供原子性和并发控制;相比传统tx, 灵活性和通用性下降,但是有更少的网络round-trip time; efficiency高. <strong>应用</strong>：原子的交换、原子的读多个数据、验证cache然后修改…<strong>TC</strong>:运行在application结点,而不是mmy结点,且TC不记log,由参与者记；将TC和app绑定,节省了网络RTT；可以容忍app结点挂掉,不会有不一致；mmy 结点挂掉,也不影响可用性和持久性；解决传统2PC下,TC挂掉后block问题. <strong>Recovery coordinator</strong>: 1.询问参与者现存vote; 2. Cmt iff 所有投票为yes. || mmy结点挂掉会block tx, 需要等其恢复.</p>
<h4 id="Intro-1"><a href="#Intro-1" class="headerlink" title="Intro"></a>Intro</h4><p><strong>Sinfonia: A NewParadigm for Building Scalable Distributed Systems</strong></p>
<p>作者称Sinfonia是一个新的用于建设分布式系统的paradigm(范式)，可以理解是分布式系统底层的架构设计，或者是底层提供的一种服务。</p>
<p>传统的分布式设计是基于<strong>message-passing</strong>，在这种设计中各个进程间通过传递消息来共享数据。这种方式的缺点是需要借助复杂的协议来处理分布式状态，协议包括replication, ﬁle data and metadata management, cache consistency, andgroup membership.这些都不简单。</p>
<p>Sinfonia 这种服务能够让host可以以一种容错，可扩展，一致的方式共享应用数据。开发者使用这种服务就不必考虑复杂的message-passing 协议。</p>
<h4 id="Sinfonia-架构"><a href="#Sinfonia-架构" class="headerlink" title="Sinfonia 架构"></a>Sinfonia 架构</h4><p><img src="file:///C:%5CUsers%5Cuser%5CAppData%5CLocal%5CTemp%5Cmsohtmlclip1%5C01%5Cclip_image002.jpg" alt="img"></p>
<p><strong>Sinfonia</strong> <strong>设计思想</strong>：</p>
<ol>
<li><p>Distributed Shared Memory as a Service</p>
</li>
<li><p>包含多个memory node ，展示出flat, fine-grained address spaces</p>
</li>
<li><p>运行在application node上的进程，通过user library 来访问服务</p>
</li>
</ol>
<p>其核心技术是mini-transactions。</p>
<h4 id="mini-transaction"><a href="#mini-transaction" class="headerlink" title="mini-transaction"></a>mini-transaction</h4><p>一句话描述</p>
<p>A lightweight, short-lived type of transaction</p>
<p><strong>改良</strong></p>
<p>传统2PC情况下，一个TC先执行一个transaction，这需要让participants执行一到多次transactions（读取或修改数据项），在这次transaction结束后，TC执行2PC。</p>
<p>在Sinfonia中，TC在application node，而participants在memory node中。作者观察到，如果一次transaction的行为不会影响到TC的决定的话，TC其实可以直接将这些操作放在2PC的第一个phase中执行（piggyback），从而减少了一次round-trip 沟通所花费的时间。</p>
<p><strong>可以**</strong>piggyback<strong>**的情况</strong></p>
<ol>
<li><p>最后一次action不会影响TC关于abort 或者commit的决定</p>
</li>
<li><p>最后一次action对TC的影响，participant已经知道</p>
</li>
</ol>
<p>​                </p>
<p><strong>细节</strong> mini transaction 包含</p>
<ol>
<li><p>set of compare items</p>
</li>
<li><p>set of write items</p>
</li>
<li><p>set of read items</p>
</li>
</ol>
<p>semantics:</p>
<ol>
<li><p>检查compare items中data（equality）</p>
</li>
<li><p>如果全部匹配</p>
</li>
</ol>
<p>​               1）获取read items中的数据</p>
<p>​               2）写write items中的数据</p>
<ol start="3">
<li>否则Abort</li>
</ol>
<p><strong>意义：</strong>相比传统的transaction，less flexible and general purpose，但是拥有fewer network round-triptime。</p>
<p>典型的应用：</p>
<ol>
<li><p>Validatecache using compare items and write if valid</p>
</li>
<li><p>Use compare items to validate data withoutread/write items; commit indicates validation was successful for read-onlyoperations</p>
</li>
</ol>
<p>总的来说，非常抽象。基本上是提供了一套机制，开发者可以利用这套机制来定制自己的策略，由于限制比较大，所以minitransaction的通用性不强，相比传统的transaction，它的expressiveness也不够好。但是在数据中心底层一些应用中还是有其适用性的（作者给予Sinfonia也实现了两个应用）。并且有比较好的efficiency。</p>
<p>基本可以看作是</p>
<p>Trade off expressiveness for efficiency</p>
<h4 id="Sinfonia的2PC和recovery-问题"><a href="#Sinfonia的2PC和recovery-问题" class="headerlink" title="Sinfonia的2PC和recovery 问题"></a>Sinfonia的2PC和recovery 问题</h4><p>如上所述哦，Sinfonia中TC运行在application node上，而不是在memory node上。</p>
<p><strong>Fault Tolerance</strong> ：</p>
<p>app node 挂掉，不会有数据丢失的情况（即，inconsistency）。</p>
<p>memory node crash，也不应该影响availability和durability。</p>
<p>这些保护都相应的由disk image，logging，replication，backup来实现。</p>
<p><strong>传统**</strong>2PC**</p>
<p>TC需要记录log，来追踪transaction 是否commit，TC crash 后，会阻塞所有的transaction。</p>
<p>这在分布式场景下明显不可取，并且Sinfornia 的TC是在App node上，app node相比memory node 要less reliable。</p>
<p>Sinfornia使用单独<strong>Recoverycoordinator**</strong>（<strong><strong>RC</strong></strong>）**</p>
<p>TC不再记录log，而是由所有participants记log，一个transaction只有在所有participants 的log都记录yes时才会commit。</p>
<p>disaster发生后，RC做clean-up工作：</p>
<p> 1）询问所有participants的existing vote</p>
<p> 2）commit iff allvote yes</p>
<p>若是memory node挂掉，则需要transaction blocks，用redo log恢复自己。</p>
<h2 id="let-7-paxos"><a href="#let-7-paxos" class="headerlink" title="let 7 paxos"></a>let 7 paxos</h2><p>拜占庭将军问题</p>
<h4 id="Intro-2"><a href="#Intro-2" class="headerlink" title="Intro"></a>Intro</h4><p>分布式系统有消息传递和内存共享两种模型。而在基于消息传递的分布式系统中，可能会发生进程被挂起，消息丢失，重发等情况。所以需要一致性算法保证一致性，使得分布式系统中即使发生了上述问题，也可以就某一个值的最终状态达到一致。当然算法比较复杂，（也就是Sinfornia论文中踩消息传递的理由）这篇论文作者用大白话给人复述了一遍。</p>
<h4 id="算法目标和前提"><a href="#算法目标和前提" class="headerlink" title="算法目标和前提"></a>算法目标和前提</h4><p>一致性算法保证所有提出的决议中，有一个决议会被最终选择。</p>
<p>如果一个决议被选中，那么所有processes最终都会知道这个被选中的决议。</p>
<p>最终保证正确性和容错性，但是不保证算法会终结。</p>
<p><strong>前提</strong>假设代理之间用消息通信，采用异步，非拜占庭模型。非拜占庭模型指的是允许消息的丢失或者重复，但是不会出现内容损坏的情况。</p>
<h4 id="算法细节"><a href="#算法细节" class="headerlink" title="算法细节"></a>算法细节</h4><p>一致性算法中的四个角色：</p>
<ol>
<li><p>client：make a request</p>
</li>
<li><p>proposer: 提出者 Get a requestand run the protocol</p>
</li>
<li><p>Leader = elected Coordinator</p>
</li>
<li><p>acceptor：批准者 Remember thestate of the protocol</p>
</li>
<li><p>Quorum = any majority of Acceptor</p>
</li>
<li><p>learner：接受者 When agreementhas been reached, a Learner executes the request and/or sends a response backto the Client</p>
</li>
</ol>
<h4 id="详细过程（具体可以参考PPT）"><a href="#详细过程（具体可以参考PPT）" class="headerlink" title="详细过程（具体可以参考PPT）"></a>详细过程（具体可以参考PPT）</h4><p>主要分成申请阶段和沟通阶段。</p>
<ol>
<li><p>client 发请求给proposer，proposer选出Leader，Leader利用编号N（比之前的都要大）发送提议（proposal）给多数 acceptor（quotum）。</p>
</li>
<li><p>对acceptor来说，若收到的编号ID &gt; 之前所有的，则1）返回之前收到的最大的proposal以及一个value，2）promise 忽略所有IDs &lt;N 的proposal；否则，直接忽视（proposal被拒绝）</p>
</li>
<li><p>对leader来说，一旦受到足够的promise，1）为proposal设置一个value V（可以使决定好的，也可以是新的）2）发送accept request 给quorum，并附带选中的V。这就到了<strong>沟通阶段</strong></p>
</li>
<li><p>acceptor ，如果promise保留着，就1）注册value V ，2）发送accepted message给proposer/learner,否则就忽略accept request这条message</p>
</li>
<li><p>最后，learner收到信息，给client 做出反应，并对request 做出action</p>
</li>
</ol>
<h4 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h4><p>To make a change to the system</p>
<ol>
<li>Tell the proposer(leader) the event</li>
</ol>
<p>(NOTE: these requests may occur concurrently)</p>
<ol>
<li><p>The leader picks its next highest ID and asksproposal to all the acceptors with that ID</p>
</li>
<li><p>When the majority of acceptors accept the proposal,accepted event are sent to learners</p>
</li>
<li><p>The learners do event (e.g., update system state)</p>
</li>
</ol>
<p>分布式系统的容错.<br><strong>ReplicatedState Machine(RSM)</strong>: may无法保证顺序一致性à采用基于primary/backup,可以保证SC,但是failure时,爆炸,因此需要一个分布式容错的共识协议.即一般情况用一套,如2PC,有failure之后用一套,如Paxos<br>.<strong>共识算法要求</strong>：正确性（所有节点同意同一个值,且该值是由某个节点提出的）、容错性（允许少数节点fail）、可终止；分布式异步场景下,无法同时满足.<br><strong>Paxos</strong>: 分布式系统有消息传递和内存共享两种模型,Paxos是基于msg传递的容错共识协议.<br><strong>前提</strong>：代理之间用消息通信,采用异步,非拜占庭模型(msg有丢失、重复,无损坏).<br><strong>目标</strong>：保证共识的正确性和容错性,无法保证算法终结.<br><strong>成员</strong>：client提出请求；proposer接收请求,发起协议；acceptor记录协议状态,共识协议投票；learner执行共识结果.<br><strong>流程：<br>**</strong>1.<strong>client 发请求给proposer,proposer选出Leader,Leader利用编号N（比之前用的都要大）发送提议proposal给多数 acceptor即quorum；提议要被quorum接收后才能真正成为leader. **2.</strong> 对acceptor来说,若收到的编号N&gt;之前见过的所有的,则1）返回之前收到的最大的proposal以及一个value,2）promise 忽略所有IDs &lt;N 的proposal；否则,直接忽视（proposal被拒绝）<br><strong>3.</strong> 对leader来说,一旦受到足够的promise,1）为proposal设置一个value V（可以是决定好的,也可以是新的）2）发送accept request 给quorum,并附带选中的V.<br><strong>4.</strong>Acceptor, 如果promise保留着(N仍然是自己见过的最大值),就1）注册value V,2）发送accepted message给proposer/learner, 否则就忽略accept request这条msg.<br><strong>5.</strong>learner收到信息,给client 做出反应,并对request 做出action.<br><strong>补充</strong>：期间协议失败,则delay and restart；一个server可能有多个角色；acceptor要记录Nh,Na,Va到log中,以便recover.</p>
<h2 id="let-8-Distributed-File-Systems"><a href="#let-8-Distributed-File-Systems" class="headerlink" title="let 8 Distributed File Systems"></a>let 8 Distributed File Systems</h2><p><strong>1.NFS</strong>：最传统的网络文件系统，支持一些简单的操作，如read和write。<a href=""><strong>设计目标如下</strong>：</a>a)任何机器都能成为客户端和服务器；支持没有硬盘的工作站（历史原因）；支持不同配置的机器；访问透明（用户访问远程的资源就像访问本地的一样）；可以从错误中恢复；具有较高的性能。<strong>Mounting protocol</strong>:所有请求访问暴露出来的目录树，具体地，客户端发送文件的路径名到服务器，服务器返回handle。<strong>关于validation</strong>：出现不一致的问题，解决方法是时间戳，当文件被打开或者服务器被连接，则比较时间戳，发现远端的时间戳更新，则invalidate掉缓存中的数据。同时，对于打开的文件，固定每3秒invalidate一次，文件夹则是30秒invalidate一次。<strong>提升读性能：</strong>每次都多返回一些读数据，预读，避免程序反复发送读邻近数据的请求。<strong>存在的问题：</strong>主要是一致性问题和服务器无状态带来的一些问题。<strong>2.GFS：</strong>运行于廉价的普通硬件上的可扩展的分布式文件系统，用于大型的、分布式的、对大量数据进行访问的应用。<strong>架构：</strong>一个GFS包括一个主服务器和多个块服务器，这样一个GFS能够同时为多个客户端应用程序提供文件服务。文件被划分为固定的块，由主服务器安排存放到块服务器的本地硬盘上。<strong>设计目标如下</strong>：可拓展性、适用于数据密集型、提供fault-tolerant<strong>设计假设：</strong>传统文件系统不再适用，因为通常支持的文件都比较小；failures非常常见；存储的文件都非常大；大多数写操作都是append而不是overwrite；大多数workload都是只读的。<strong>块和块服务器：</strong>块大小一般是64MB，块的handle由主服务器负责分发，块的本质是一个Linux系统中的本地文件，每一个块文件在不同的Node中进行冗余。<strong>主服务器：</strong>主服务器会记录存放位置等数据，并负责维护和管理文件系统，包括块的租用、垃圾块的回收以及块在不同块服务器之间的迁移。但是，主服务器不会持久化所有块的位置，因为块的位置在各个块服务器可能会发生变动，持久化后容易发生不一致的问题，解决访问只能是定期访问所有的块服务器。同样需要对主服务器进行备份冗余，通过心跳信息定期与所有节点进行通信。<strong>块规模：</strong>较大的原因1.减少客户端和主服务器之间的交互。因为读写同一个块只要在开始时向主服务器请求块位置信息，大的块可以减少请求的次数，对于读写大型文件这种减少尤为重要。2.客户端在一个给定的块上很可能执行多个操作，和一个块服务器保持较长时间的TCP连接可以减少网络负载。3.减少了master上保存的元数据的规模，从而使得可以将metadata放在内存中。<strong>读写操作：</strong>读操作:与主服务器建立连接;获取元数据（主要是handle）；获取handle所在的位置；与相应的块服务器建立连接。写操作：第一阶段（数据流阶段），发送数据，发送到多个块服务器，数据暂时存在缓存中；第二阶段（控制流阶段），写入数据，发送完成后，各个块服务器将数据写入硬盘中，这个过程中会有一个primary<a href="">块服务器</a>来接受客户端的写操作请求，并通知各个其他块服务器序列化写操作。<strong>3.Chubby：</strong>Chubby能够提供机制使得client可以在Chubby service上创建文件和执行一些文件的基本操作。说它是分布式的文件系统，是因为一个Chubby cell是一个分布式的系统，一般包含了5台机器，整个文件系统是部署在这5台机器上的。从更高一点的语义层面上，Chubby是一个针对松耦合的分布式系统的lock service。它提供了文件访问、事件通知和文件锁等服务。<strong>适用于：</strong>粗粒度的、长期持有的锁；数量较少的数据，如系统的配置文件。<strong>主服务器：</strong>用Paxos协议来选择主服务器；如果超过了租约事件或者发生了failures,则重新用Paxos来选择主服务器。<strong>文件系统的接口：</strong>Chubby的文件系统和UNIX类似，例如在文件名“/ls/foo/wombat/pouch”中，ls代表lock service，这是所有Chubby文件系统的共有前缀；foo是某个单元的名称；/wombat/pouch则是foo这个单元上的文件目录或者文件名。<strong>锁服务：</strong>Chubby系统本质上就是一个分布式的、存储大量小文件的文件系统，它所有的操作都是在文件的基础上完成。Chubby最常用的锁服务中，每一个文件就代表一个锁，用户通过打开、关闭和读取文件，获取共享（Shared）锁或独占（Exclusive）锁；选举主服务器过程中，符合条件的服务器都同时申请打开某个文件并请求锁住该文件；成功获得锁的服务器自动成为主服务器并将其地址写入这个文件夹，以便其他服务器和用户可以获知主服务器的地址信息。这里的锁是建议锁不是强制性的锁，有更大的灵活性。<strong>缓存机制：</strong>客户端会保存文件数据和节点的元数据在一个一致的，采用的write-through的缓存中。在客户端保存一个和单元上数据一致的本地缓存。当某个文件数据或者元数据需要修改时，主服务器首先将这个修改阻塞；然后通过查询主服务器自身维护的一个缓存表，向对修改的数据进行了缓存的所有客户端发送一个Invalidation。客户端收到这个无效标志后会返回一个确认Acknowledge，主服务器在收到所有的确认后才解除阻塞并完成这次修改。</p>
<h2 id="let-9-data-parallel"><a href="#let-9-data-parallel" class="headerlink" title="let 9 data parallel"></a>let 9 data parallel</h2><p><strong>1.MapReduce</strong> 核心编程结构map函数：Map(input shard)-&gt;intermediate(k/v pairs)，将数据划分为M个shards，然后将相同Key的value集合起来发送到reduce阶段。Reduce函数：intermediate(k/v<br>pairs)-&gt;(results)利用划分函数将中间结果划分到R个块上，如hash(key) mod R，然后将排序后的键值对根据特定Key合并value值。<strong>一次MapReduce的流程：</strong>1.把输入文件划分为M份（M为用户定义），每一份通常有16MB到64MB；然后使用fork将用户进程拷贝到集群内其它机器上。2.user program的副本中有一个称为master，其余称为worker，master是负责调度的，为空闲worker分配任务，worker的数量也是可以由用户指定的。3.被分配了Map作业的worker，开始读取对应分片的输入数据，Map作业数量是由M决定的，和split一一对应；Map作业从输入数据中解析出键值对，每一个键值对都作为参数传递给map函数，map函数产生的中间键值对被缓存在内存中。4.缓存在内存中的中间键值对会被定期写入本地磁盘，而且被分为R个区，R的大小是由用户定义的，将来每个区会对应一个Reduce作业；这些中间键值对的位置会被通报给master，master负责将信息转发给Reduce worker。5.master通知分配了Reduce作业的worker它负责的分区在什么位置，当Reduce worker把所有它负责的中间键值对都读过来后，先对它们进行排序，使得相同键的键值对聚集在一起。因为不同的键可能会映射到同一个分区也就是同一个Reduce作业，所以排序是必须的。6.reduce worker遍历排序后的中间键值对，对于每个唯一的键，都将键与关联的值传递给reduce函数，reduce函数产生的输出会添加到这个分区的输出文件中。7.当所有的Map和Reduce任务都完成了，master唤醒user program，MapReduce函数调用返回user program的代码。<strong>Locality:</strong>输入输出文件都建立在GFS上；在GFS的chunkservers上运行协调计算和存储，提高数据的本地性。<strong>Fault Tolerance:</strong>Master会定期ping所有的worker，如果在特定的时间内收不到回复则认为该workerfailed，然后reset该worker并re-execution；如果Mater出现failure则由GFS根据checkpoint进行恢复。<strong>Straggler:</strong>执行速度慢的worker会极大地影响整个工作的时长，出现这种情况的原因喝多：如资源被其他任务抢占、硬盘坏道、没有打开缓存等等；解决方法：copy该执行缓慢worker的状态和数据，由其他worker执行，谁先执行完成就用谁的结果。<strong>存在的问题：</strong>只能完成一个完整的mapreduce才能进行下一个阶段，这一个阶段可能时间很长，对时效性高的需求不适用，解决办法是提出了caffeine的框架。</p>
<p><strong>2.Dryad</strong>：将计算过程表现为图，其中顶点代表计算，边代表通信通道，每个顶点有若干条入边和出边。因为很多程序用数据流图的形式表示更合适，所以该模型基础就是将程序执行过程表示为一个有向无环图。用户通过实现自定义的Vertex节点来执行定制的运算逻辑，而节点之间通过各种形式的数据通道传输数据，用户的运算逻辑本身通常是顺序执行的，而与分布式相关的逻辑则由Dryad框架来实现。<strong>运行过程：</strong>1.顶点：可以运行任意的程序代码，通过tcp各个计算节点之间通过例如文件，管道，网络等形式的通道交换数据，并定期与JM通信；2.JM在应用程序内部维护了一个基于DAG图模型的计算节点依赖关系图，JM通过命名服务器NS来获取可用的服务器列表，而后通过在这些服务器上运行的守护进程Daemon来调度和执行计算节点Vertex。3.守护进程Daemon，运行各个顶点上的计算任务。<strong>JM的调度：</strong>如果输入数据已经准备好，一个顶点可以随时进行计算，同时尽量将数据置于计算节点的本地，提高数据的locality。<strong>Fault-tolerance：</strong>如果节点出现fail，则重新运行一次；如果节点的输入数据消失，则递归地执行之前依赖的节点计算过程，直到所有输入数据重新准备好；如果某个节点计算很慢，和mapreduce中一样，起其他一个节点执行相同的代码和输入数据，谁先完成则使用谁的结果。<strong>优势：</strong>适合更加大型复杂的任务，有向图的形式对于多个阶段的任务可以减少不必要的通信和数据的冗余。更加灵活，可以支持join操作。</p>
<h2 id="let-10-Pregel-amp-GraphLab"><a href="#let-10-Pregel-amp-GraphLab" class="headerlink" title="let 10 Pregel&amp;GraphLab"></a>let 10 Pregel&amp;GraphLab</h2><p>图并行计算算法具有dependency graph，predictableupdates，iterative computation等特征，mapreduce等并行计算模型在实现这些算法是非常的困难和低效(mapreduce处理迭代很低效率)，所以本文在现有的图计算模型graphlab和pregel的基础上提出了distributed graphlab。</p>
<p><strong>Pregel</strong>采用了bulk synchronous parallelmodel, vertex之间的通信通过message-passing实现。对于每个vertex来说计算过程如下：1，接受上一步收到的邻居节点发送的消息；2，执行用户定义的update function；3，修改自身的value；4，如果该节点是active的（尚未收敛），向邻居节点发送消息；5，如果该节点是inactive的，投票halt。所有节点之间的barrier synchronization由master来完成，当所有vertex投票halt的时候，计算终止。<strong>架构</strong>:master-slave.<strong>缺点</strong>:straggler;通信量大,有不必要的通信.<strong>Pregel的整体性能受计算最慢的机器限制</strong>。同步计算，每次都要给邻居发消息(即使不需要)，造成不必要的通信，并且每次迭代都会受最慢的机器限制。</p>
<p><strong>GraphLab</strong>:async计算(邻居改变时才evaluate comdition,同步需要每阶段对每个顶点evaluate);通过shared mmy通信; 每个vertex可以直接访问自身及邻居边、邻居节点的数据,可以根据自身的执行结果来调度邻居vertex的后续执行; serializability通过防止邻居节点同时执行来实现. <strong>Data Graph</strong>:存在mmy,支持快速随机查找;Ghost顶点维持顶点局部结构,复制远端数据.<strong>Partition</strong>: 首先使用random hashing等方法将graph分为k部分（k远大于机器数）,每部分叫做一个atom,作为一个文件存储在分布式存储系统上（HDFS等）.每个atom中还需要存储ghosts信息,k个atom之间的连接关系存储在一个叫做meta-graph的文件中.在将graph信息load进机器内存时,先按照机器数量对meta-graph做一个balanced partition,然后每台机器按照对应atom的信息建立graph的局部结构. <strong>更新函数</strong>:用户定义,运行在顶点,只涉及顶点scope数据. <strong>Scheduler</strong>:决定顶点更新顺序(FIFO/Priority/Round Robin). <strong>一致模型**</strong>/<strong>**并行度</strong>:1. Full consistency:点、边、邻居节点.2. Edge consistency:点、边.3. Vertex consistency:点. <strong>执行</strong>engine**: 负责执行update function和sync operation,维持一个被调度的vertex集合,并按照给定的一致性模型来保证serializability. 1. chromatic engine:按照对应的serializability要求对节点使用贪心法进行染色,相同颜色的节点可以同步执行,同一颜色的节点执行完成之后才可以开始执行下一种颜色的节点. 2. distributed locking engine：每个vertex有一个read-write lock,在vertex consistency中只需要获得central vertex的write-lock；在edge consistency中需要获得central vertex的write-lock及相邻两个vertex的read-lock；在full consistency中需要获得central vertex和相邻两个vertex的write-lock; 3.dead lock可以通过按一定顺序拿锁来获取. 4. pipelined locking and prefetching: 为了减少远程锁请求和数据同步的时延, 每台机器维持一个pipeline, pipeline中的所有vertex同时请求锁,哪个vertex先拿到锁就先执行,而不是所有vertex按顺序执行.</p>
<p><strong>Graphlab</strong>是一种异步并行模型，vertex之间的通信通过shared-memory实现。每个vertex可以直接访问自身及邻居边、邻居节点的数据，可以根据自身的执行结果来调度邻居vertex的后续执行，serializability通过防止邻居节点同时执行来实现。</p>
<p><strong>Distributed graphlab</strong>基于graphlab实现，改模型主要包含三个部分：data graph, update function, synchronization. 其中data graph的划分和构造分两步实现：首先使用random hashing等方法将graph分为k部分（k远大于机器数），每部分叫做一个atom，作为一个文件存储在分布式存储系统上（HDFS等）。每个atom中还需要存储ghosts信息，k个atom之间的连接关系存储在一个叫做meta-graph的文件中。在将graph信息load进机器内存时，先按照机器数量对meta-graph做一个balanced partition，然后每台机器按照对应atom的信息建立graph的局部结构。Updatefunction是一个用户自定义的程序，它根据vertex自身及邻居数据来迭代更细当前vertex的数据。</p>
<p>Distributed graphlab中分三种层次的serializability：1,Full consistency,  2, edgeconsistency,  3,vertex consistency</p>
<p><strong>distributed graphlab**</strong>中有两种执行engine，engine**负责执行update function和sync operation，维持一个被调度的vertex集合，并按照给定的一致性模型来保证serializability.</p>
<p>（1））chromatic engine:按照对应的serializability要求对节点使用贪心法进行染色，相同颜色的节点可以同步执行，同一颜色的节点执行完成之后才可以开始执行下一种颜色的节点。对于vertex consistency，所有节点染成同一颜色；对于edge consistency，任何两个相邻节点不能染成相同颜色；对于full consistency，距离为2及2以内的节点不能染成相同颜色。</p>
<p>（2））distributed locking engine：每个vertex有一个readers-writer lock，在vertex consistency中只需要获得central vertex的write-lock；在edge consistency中需要获得central vettex的write-lock及相邻两个vertex的read-lock；在fullconsistency中需要获得central vertex和相邻两个vertex的write-lock；deadlock可以通过按一定顺序拿锁来获取，具体来说，拿锁顺序有machine ID及vertex ID（owner（v），v）决定。</p>
<p>为了减少remote lock acquisition和data synchronization的时延，采用了pipelined lockingand prefetching: 每台机器维持一个pipeline，用于存放该机器上所有请求锁但是还没有获得锁的vertex，当一个vertex获得锁并完成数据同步后就离开这个pipeline然后有一个工作线程去执行。（即pipeline中的所有vertex同时请求锁，哪个vertex先拿到锁就先执行，而不是所有vertex按顺序执行，具体实现中采用的不是readers-writer lock，而是通过操作callback来实现的readers-writer lock的一个非阻塞版本）</p>
<h2 id="lec-11-PowerLyra"><a href="#lec-11-PowerLyra" class="headerlink" title="lec 11 PowerLyra"></a>lec 11 PowerLyra</h2><p>不同的划分对网络IO会有较大影响。</p>
<p>现实中的图大都是skewed，即大多数节点的邻居较少，少部分节点的邻居非常多。在一个机器集群中进行图的分布式计算时必然涉及到对图的分割。现有的分割图的方案主要有两种，即edge-cut和vertex-cut。Edge-cut将vertex均匀地分布在各个机器上，每个vertex对应的edge也随vertex分布在相应的机器上，如果同一个edge的对应的两个vertex分布在两台机器上，则该edge在这两台机器上各有一个拷贝，在edge-cut中，大部分vertex所需要的计算资源都在本地机器，所以在计算时可以充分利用locality，但是这种分割方案缺乏parallelism，度数特别大的可能成为瓶颈。Vertex-cut将edge均匀地分布到各个机器上，如果一个vertex的几个edge在不同的机器上，那么该vertex在这几台机器上都会有拷贝，在vertex-cut中，一个vertex可能分布在好几台机器上，所以计算时可以充分利用parallelism，将一个vertex的负载分散到多个机器上，但是缺乏locality，网络时延大。现有的图分割方案大都是“one size fit all”，所有的节点被平等对待，为了使尽可能地利用locality和parallelism，本文将low-degree和high-degree的区别对待，将edge-cut和vertex-cut结合起来，提出了hybrid-cut。在hybrid-cut中，对于low-degree vertex，尽量减少vertex的mirror数量，尽可能地利用locality；对于high-degree vertex，主要考虑负载均衡，是计算并行进行。具体来说，先按vertex编号及机器数量将vertex均匀地哈希到所有机器上，所有edge按照其入度跟随vertex分布到相应机器上，在这个过程中，记录所有vertex的入度；然后设定一个threshold，入度超过这个threshold的vertex是high-degree vertex；对于high-degree vertex，将其入边按照source vertex重新hash到对应机器，及high-degree vertex的入边跟随其source vertex；最后建立mirrors来完成每台机器上local graph的创建。</p>
<p><strong>通信</strong>:1.高度数,&lt;= 4*mirrors(有一个mirror就有4次 Gather2次,Scatter2次)(powerGraph是5,将apply和scatter1结合);2.低度数, &lt;=1*#mirrors (Scatter, master-&gt;mirror);若G&amp;S阶段需要双向edge,根据需要逐步在G&amp;S阶段增加master和mirror之间的通信,总数最多不超过4次.</p>
<p>按照hybrid-cut对图进行划分后，计算时所有vertex都采用GAS计算模型，在high-degree vertex中，负载被分散在多台机器上，从而保证负载均衡；在low-degree vertex中，所有计算都在本地机器完成，只在scatter阶段需要master和mirror之间的通信。</p>
<p>对于low-degree vertex，上述模型只考虑了单方向的locality，为了使改模型更通用，可以根据具体算法的需要，在scatter和gather阶段master和mirror之间的通信，但是增加的额外通信message数不会超过3.，</p>
<p><strong>参考ADS 10 -12</strong></p>
<h2 id="let-12-GraphChi"><a href="#let-12-GraphChi" class="headerlink" title="let 12 GraphChi"></a>let 12 GraphChi</h2><p><strong>背景</strong>:分布式程序难写;有效扩展的需求(传统多台机子一次一个task,一个机子一个task的话更易扩展); Cost; Energy. <strong>目标</strong>:单台机子,reasonable时间,大规模图计算.<strong>挑战</strong>:磁盘的随机访问.若以对称邻接文件的方式存储graph, 需要每秒数百万次的磁盘随机访问, SSD也满足不了,因此提出PSW. <strong>Parallel Sliding Windows(PSW)</strong>:1个应用分多个迭代执行完,之前是一个迭代完成整张图的一次计算,现将图分为sub-graph,一个迭代分为多个小迭代执行一个sub-graph,每个小迭代为loadàcomputeàwrite. 流程:1. 所有的顶点依次被编号为1-N, 按顺序分为P个interval,一个sub-graph对应一个interval,每个interval在disk上有一个对应的shard.(每个shard的size足够小,刚好放入内存中; 一个shard中存储其所对应的interval中的所有顶点及其入边; 入边按source顶点排序,使得顶点的出边在每个shard中顶点编号顺序存储). 每个interval需要P次large读, 每次迭代总共需要P2次顺序读. 2. 计算阶段,  本次计算结果下个interval可见,即sub-graph之间是异步的, sub-graph内部均可(不同interval之间同步，同一个interver之内异步). 3.更新写回disk,保证下个shard可见,一次迭代有P2次顺序写.<br><strong>Evolving Graph</strong>:新加入/删除边. 每个interval有一个edge-buffer,新加的edge会被临时存放在edge-buffer中,删除的边被标记为”removed”, 当edge-buffer满了的时候,shard会被在磁盘上recreated,太大的shard会被重新分割为较小的shard,在recreate的过程中,“removed”边会被永久删除. <strong>总结</strong>:PSW可以处理大规模图with很少随机disk访问; 合适的数据结构来scale up</p>
<h2 id="let-13-Tiled-MapReduce"><a href="#let-13-Tiled-MapReduce" class="headerlink" title="let 13 Tiled-MapReduce"></a>let 13 Tiled-MapReduce</h2><p><strong>背景</strong>：多核处理器普及,可以在单机上实现数据并行应用.<strong>并行优化points</strong>:运行算法、可扩展的数据结构、OS交互.<strong>Phoenix</strong>:<br>利用thread实现并行,利用共享地址空间进行通信.<strong>数据结构</strong>：Intermediate Buffer,矩阵结构.行对应thread,列为key；mapper按行,reducer按列,因此同阶段内数据不冲突,无需加锁；表内为指针指向mmy中数据,降低数据传输开销.<strong>缺陷</strong>：1.内存开销大.需要把整个输入数据都放在内存.2.数据locality差.一次处理全部输入数据,cache不停重刷,reduce相当于面对空cache.3.严格依赖barriers. map全部结束才可以reduce.<strong>TMR</strong>：<strong>Tiling策略</strong>：将大的job拆分为小的sub-job,迭代处理,每次一个sub-job,要求reduce函数是Commutative和Associative. <strong>流程</strong>：1.map.只加载部分输入数据,够sub-job用,将结果存入Intermediate Buffer(IB).2. combine.处理IB中的列,存入Iteration<br>Buffer.1&amp;2循环处理所有子任务. 3.reduce.处理Iteration Buffer,存入Final Buffer.<strong>优点</strong>：并发提高；cache、mmy利用率提高.<strong>缺点</strong>：计算次数增大.<strong>优化</strong>：1.Mmy<br>Reuse. mmy中只存当前子任务需要的数据；不同子任务重用input buffer和IB；重用IB之前,将必需数据复制集中到一起,new buffer（不再用指针）；加入compress阶段自动合并不同combine结果,减少内存占用. 2.数据locality. 每个子任务的working set刚好放在最后一级cache里,使map相当于为reduce预取数据；1中在combine阶段集中必要数据；NUCA/NUMA-Aware Scheduler（以往的问题是用多个核来处理同一个job,现在只要让subjob跑在同一个核上,并只用该核的内存即可；先按core分为不同repeater,然后core内再分worker,Repeater的Job Buffer、Intermediate Buffer、Iteration<br>Buffer都是私有的；将subjob切分得小,通过work-stealing 机制,实现repeater的负载均衡）3. Software Pipeline: map阶段能者多劳,负载较为均衡,但是reduce阶段,key数量少时,可能不均衡；下一个子任务的map与前一个的combine阶段无数据依赖,可以pipeline；子任务间重用IB的依赖,可以用dual buffer消除. 4. Thread Pool: 子任务重用线程</p>
<h2 id="let-14-Replication-based-fault-tolerance-Imitator"><a href="#let-14-Replication-based-fault-tolerance-Imitator" class="headerlink" title="let 14  Replication-based fault tolerance(Imitator)"></a>let 14  Replication-based fault tolerance(Imitator)</h2><p><strong>背景</strong>：图变大,由于scale大,运行时间长,容错很重要.<strong>BSP流程(图计算)</strong>：Load计算(master) SendMsg(master和replica)(EnterBarrier, Commit, LeaveBarrier),完成CMT,保证结果在下次迭代可见.<strong>容错技术</strong>：1. MapReduce：Simple re-execution. 分给别的worker执行,谁先commit用谁的.问题：只支持确定性、独立的任务,无法处理强依赖. 2. Spark：使用Resilient Distributed Datasets,粗粒度操作,log只记录操作.问题：没有data,不支持细粒度. 3. Checkpoint. (incremental CKPT) 同步中所有节点在global barrier处生成snapshot,异步中以固定时间间隔启动生成.恢复时从metadata snapshot加载图拓扑,从data snapshot更新点和边状态.问题：大开销,慢恢复（一台机器挂,所有机器都要回滚,带来大量读写、IO、同步开销,需要standby node；受限于单机IO；同步中的global barrier不平衡可通过降低打log频率缓解,但会导致恢复时间变长）<strong>Imitator</strong>:<strong>设计思想</strong>：几乎所有节点都有replicas,并且均匀分布在多台机器上.可以重用它们来做recovery.实现：扩展同步msg部分,添加检测.1.Failure before barrier：enter时发现,新建一个机器取代它,其它机器需要回滚到迭代开始,因为一些消息可能因为crash丢了. 2.Failure after barrier：leave时发现,新建一个机器取代它,redo先前流程.<strong>Fault tolerant (FT) replica</strong>：对没有replica的顶点在load图时建立FT replica；位置保证负载均衡；<strong>selfish<br>vertice</strong>：即无出边,只需建立FT replica,无需和master同步,恢复时从FT拿静态信息,动态信息通过邻居节点重新计算.<strong>Full-state<br>Replica (Mirror)</strong>：于master等价；由于普通的replica缺乏meta信息,选择一个mirror存放,负责恢复maste；贪婪分布在mirror少的node上.<strong>恢复目标：</strong>并行恢复；恢复后状态一致.<strong>恢复策略</strong>：<strong>1.<br>Rebirth</strong>.<strong>规则</strong>:master恢复replicas; mirror恢复master;需要standby结点. <strong>流程</strong>：Reloading(活着的点并行检查哪些结点挂掉了,并行发送消息给standby帮助其恢复)-Reconstruction(计算,重构图)-Replay(重做操作来得到最新状态,比如active,和mirror同步时可能还未收到该消息,于是在收到后要发给mirror,这样恢复时mirror会发给它replay) <strong>缺点</strong>：需要Standby；恢复慢,reconstruct/replay阶段不可并行. <strong>2. Migration</strong>.<br>挂后将它所属的数据分布到剩余机器上,比如master挂对应mirror就被提升为master,在它们之上重建图结构.<strong>流程</strong>：Reloading(提升mirror,广播New replicas/Edges from old replicas to the new master/Edges between<br>masters)-Reconstruction(利用消息在剩余机器上重构)-Replay(只需激活被提升成master的节点,自己有激活消息,直接恢复) <strong>优点</strong>：三个阶段都可并行.<strong>总结</strong>：低开销（利用现有的replica）、恢复快（并行恢复）</p>
<h2 id="lec-extra-sandbox"><a href="#lec-extra-sandbox" class="headerlink" title="lec extra sandbox"></a>lec extra sandbox</h2><p>Royan提供了一个分布式的sandox，利用intel SGX技术保护各个sandbox不被恶意的程序估计；而各个sandbox(nacl)用于保证用户的敏感信息不会在各个平台使用时被泄露出去。Royan是请求为导向的，对每次一个请求只执行一次并不保存任何状态。<strong>threat model:</strong>只信任Ryoan和intel SGX。<strong>Intel SGX:</strong>enclave是被保护的区域，只能被enclave code访问，Ryoan实例就运行在enclave中。通过利用SGX，Ryoan可以保证用户隐私数据在不被信任的平台被使用。<strong>问题：</strong>1.平台可以读用户的私密信息。Sol:enclave可以保护不被外部读数据；2.平台可以将整段encalve中的私密信息复制到不被enclave保护的区域。Sol:nacl限制了sandbox的访问控制。3.利用sys call将私密信息直接写到未被保护的区域。Sol:对sandbox访问的sys<br>call获得的数据都进行加密。4.串通或者伪造用户窃取数据。Sol：royan是不保存任何请求的状态，即每次都会经历初始化-读入数据-处理-输出数据-销毁的过程。<strong>旁路攻击：</strong>解决方法是尽量移除module的system calls，同时保证执行所有输入和输出数据的过程是与数据内容无关的。与第4个问题的解决方法相似，中间有个问题就是初始化阶段overhead很大，优化方法是对初始化阶段做checkpoint这样处理重复请求可以节约时间，但是其他阶段仍然保持无状态，每次都重新执行。同时，一些不可避免的system call则换成功能受限的sys call，如mmap和open、write等“new”sys call则返回预先申请好的安全的内存或者文件。</p>
<h2 id="考试题型"><a href="#考试题型" class="headerlink" title="考试题型"></a>考试题型</h2><p>某个概念是什么</p>
<p>给定一个场景，让你提出解决方案</p>

      
      <!-- 打赏 -->
      
    </div>
    <footer class="article-footer">
      <a data-url="https://zkdingme.github.io/2020/06/23/ADS-Notes/" data-id="ckse3iuzf000ooqj5476ohkoe"
        class="article-share-link">分享</a>
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ADS/" rel="tag">ADS</a></li></ul>

    </footer>

  </div>

  

  
  
  

  

</article>
    
    <article id="post-docker迁移-var-lib-docker" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2020/05/19/docker%E8%BF%81%E7%A7%BB-var-lib-docker/"
    >docker迁移/var/lib/docker</a
  >
</h2>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/05/19/docker%E8%BF%81%E7%A7%BB-var-lib-docker/" class="article-date">
  <time datetime="2020-05-19T08:51:26.000Z" itemprop="datePublished">2020-05-19</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/docker/">docker</a>
  </div>

      
      
      
    </div>
    

    

    <div class="article-entry" itemprop="articleBody">
      


      

      
      <p>第一步，停止docker服务</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">systemctl stop docker</span><br><span class="line">ps aux | grep -i docker | grep -v grep // 结果为空则说明服务已经停止</span><br></pre></td></tr></table></figure>

<p>第二步，将/var/lib/docker迁移到新的文件夹</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync -aqxP /var/lib/docker /mnt/datadrive/</span><br></pre></td></tr></table></figure>

<p>第三步，修改docker启动脚本</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">vim /lib/systemd/system/docker.service</span><br><span class="line"></span><br><span class="line">FROM:</span><br><span class="line">ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock</span><br><span class="line">TO:</span><br><span class="line">ExecStart=/usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock --graph=/mnt/datadrive/docker</span><br></pre></td></tr></table></figure>

<p>第四步，重启docker</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">systemctl daemon-reload</span><br><span class="line"> </span><br><span class="line">systemctl restart docker</span><br><span class="line"> </span><br><span class="line">systemctl enable docker  //开机启动</span><br></pre></td></tr></table></figure>

<p>第五步, 启动后确认没问题，删除旧的/var/lib/docker</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rm -rf /var/lib/docker</span><br></pre></td></tr></table></figure>

<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><p><a href="https://linuxconfig.org/how-to-move-docker-s-default-var-lib-docker-to-another-directory-on-ubuntu-debian-linux" target="_blank" rel="noopener">https://linuxconfig.org/how-to-move-docker-s-default-var-lib-docker-to-another-directory-on-ubuntu-debian-linux</a></p>
<p><a href="https://my.oschina.net/qbj/blog/2998164" target="_blank" rel="noopener">https://my.oschina.net/qbj/blog/2998164</a></p>

      
      <!-- 打赏 -->
      
    </div>
    <footer class="article-footer">
      <a data-url="https://zkdingme.github.io/2020/05/19/docker%E8%BF%81%E7%A7%BB-var-lib-docker/" data-id="ckse3iuzu001moqj50xsfhp7y"
        class="article-share-link">分享</a>
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E8%BF%81%E7%A7%BB-var-lib-docker/" rel="tag">迁移/var/lib/docker</a></li></ul>

    </footer>

  </div>

  

  
  
  

  

</article>
    
  </article>
  

  
  <nav class="page-nav">
    
    <a class="extend prev" rel="prev" href="/page/3/">上一页</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/5/">下一页</a>
  </nav>
  
</section>
</div>

      <footer class="footer">
  <div class="outer">
    <ul class="list-inline">
      <li>
        &copy;
        2020-2021
        Bonjour Ding
      </li>
      <li>
        
          Powered by
        
        
        <a href="https://hexo.io" target="_blank">Hexo</a> Theme <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul class="list-inline">
      <li>
        
        
        <ul class="list-inline">
  <li>PV:<span id="busuanzi_value_page_pv"></span></li>
  <li>UV:<span id="busuanzi_value_site_uv"></span></li>
</ul>
        
      </li>
      <li>
        <!-- cnzz统计 -->
        
      </li>
    </ul>
  </div>
</footer>
    <div class="to_top">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>
      </div>
    </main>
      <aside class="sidebar">
        <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/favicon.ico" alt="丁星乐"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/2020/01/31/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
      </aside>
      <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
      
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/jquery.justifiedGallery.min.js"></script>


<script src="/js/lazyload.min.js"></script>


<script src="/js/busuanzi-2.3.pure.min.js"></script>



<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="https://cdn.jsdelivr.net/npm/typed.js@2.0.11/lib/typed.min.js"></script>
<script>
  var typed = new Typed("#subtitle", {
    strings: ['芒焰藏于简单之中','江山如此多娇','会当击水三千里，自信人生二百年'],
    startDelay: 0,
    typeSpeed: 200,
    loop: true,
    backSpeed: 100,
    showCursor: true
    });
</script>




<script>
  var ayerConfig = {
    mathjax: true
  }
</script>


<script src="/js/ayer.js"></script>


<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">


<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>



<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.6/unpacked/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


<script type="text/javascript" src="https://js.users.51.la/20544303.js"></script>
  </div>
</body>

</html>